{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec8c08f",
   "metadata": {},
   "source": [
    "# Matrix-Based Notebook Execution in Production\n",
    "\n",
    "This notebook demonstrates how to implement **matrix-based execution** for Jupyter notebooks in production CI/CD environments. Each notebook runs in its own isolated GitHub Actions runner with its specific dependencies.\n",
    "\n",
    "## 🎯 Key Benefits\n",
    "\n",
    "- **Isolation**: Each notebook runs independently\n",
    "- **Scalability**: Parallel execution across multiple runners\n",
    "- **Dependency Management**: Each notebook uses its own `requirements.txt`\n",
    "- **Fault Tolerance**: One failing notebook doesn't affect others\n",
    "- **Resource Optimization**: Different notebooks can use different runner types\n",
    "\n",
    "## 📋 Prerequisites\n",
    "\n",
    "- GitHub Actions workflows\n",
    "- Notebooks organized in separate directories\n",
    "- Individual `requirements.txt` files per notebook directory\n",
    "- Proper repository structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3426571b",
   "metadata": {},
   "source": [
    "## 📁 Repository Structure\n",
    "\n",
    "For matrix-based execution, organize your repository with each notebook in its own directory:\n",
    "\n",
    "```\n",
    "repository/\n",
    "├── .github/workflows/\n",
    "│   └── notebook-matrix.yml\n",
    "├── notebooks/\n",
    "│   ├── data-analysis/\n",
    "│   │   ├── analysis.ipynb\n",
    "│   │   ├── requirements.txt\n",
    "│   │   └── README.md\n",
    "│   ├── visualization/\n",
    "│   │   ├── plots.ipynb\n",
    "│   │   ├── requirements.txt\n",
    "│   │   └── data/\n",
    "│   ├── machine-learning/\n",
    "│   │   ├── model.ipynb\n",
    "│   │   ├── requirements.txt\n",
    "│   │   └── models/\n",
    "│   └── astronomy/\n",
    "│       ├── jwst-analysis.ipynb\n",
    "│       ├── requirements.txt\n",
    "│       └── data/\n",
    "├── _config.yml\n",
    "├── _toc.yml\n",
    "└── README.md\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "- Each notebook has its own directory\n",
    "- Each directory contains a `requirements.txt` with specific dependencies\n",
    "- Notebooks can have their own data/supporting files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d46934",
   "metadata": {},
   "source": [
    "## 1. Define Matrix List\n",
    "\n",
    "The GitHub Actions matrix strategy allows you to run the same job with different parameters. Here's how to define a matrix for notebook execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example GitHub Actions workflow matrix configuration\n",
    "# This would be in .github/workflows/notebook-matrix.yml\n",
    "\n",
    "matrix_config = {\n",
    "    \"strategy\": {\n",
    "        \"fail-fast\": False,  # Don't stop all jobs if one fails\n",
    "        \"matrix\": {\n",
    "            \"notebook\": [\n",
    "                \"notebooks/data-analysis\",\n",
    "                \"notebooks/visualization\", \n",
    "                \"notebooks/machine-learning\",\n",
    "                \"notebooks/astronomy\"\n",
    "            ],\n",
    "            \"python-version\": [\"3.9\", \"3.10\"],\n",
    "            \"os\": [\"ubuntu-latest\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display the matrix configuration\n",
    "import json\n",
    "print(\"Matrix Configuration:\")\n",
    "print(json.dumps(matrix_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ebdf86",
   "metadata": {},
   "source": [
    "### Complete GitHub Actions Workflow\n",
    "\n",
    "Here's a complete workflow file that implements matrix-based notebook execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete GitHub Actions workflow for matrix-based notebook execution\n",
    "workflow_yaml = '''\n",
    "name: Matrix Notebook Execution\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main, develop ]\n",
    "  pull_request:\n",
    "    branches: [ main ]\n",
    "  workflow_dispatch:\n",
    "    inputs:\n",
    "      notebook_path:\n",
    "        description: 'Specific notebook directory to test (optional)'\n",
    "        required: false\n",
    "        type: string\n",
    "\n",
    "jobs:\n",
    "  discover-notebooks:\n",
    "    runs-on: ubuntu-latest\n",
    "    outputs:\n",
    "      matrix: ${{ steps.discover.outputs.matrix }}\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Discover changed notebooks\n",
    "        id: discover\n",
    "        run: |\n",
    "          # Find all notebook directories with requirements.txt\n",
    "          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ] && [ -n \"${{ inputs.notebook_path }}\" ]; then\n",
    "            # Manual trigger for specific notebook\n",
    "            echo \"matrix={\\\"notebook\\\":[\\\"${{ inputs.notebook_path }}\\\"],\\\"python-version\\\":[\\\"3.9\\\"],\\\"os\\\":[\\\"ubuntu-latest\\\"]}\" >> $GITHUB_OUTPUT\n",
    "          else\n",
    "            # Auto-discovery based on changed files or all notebooks\n",
    "            notebooks=$(find notebooks -name \"requirements.txt\" -exec dirname {} \\; | sort | uniq)\n",
    "            matrix_json=$(echo \"$notebooks\" | jq -R -s -c 'split(\"\\n\")[:-1] | {\"notebook\": ., \"python-version\": [\"3.9\"], \"os\": [\"ubuntu-latest\"]}')\n",
    "            echo \"matrix=$matrix_json\" >> $GITHUB_OUTPUT\n",
    "          fi\n",
    "\n",
    "  execute-notebooks:\n",
    "    needs: discover-notebooks\n",
    "    runs-on: ${{ matrix.os }}\n",
    "    strategy:\n",
    "      fail-fast: false\n",
    "      matrix: ${{ fromJson(needs.discover-notebooks.outputs.matrix) }}\n",
    "    \n",
    "    steps:\n",
    "      - name: Checkout repository\n",
    "        uses: actions/checkout@v4\n",
    "        \n",
    "      - name: Set up Python ${{ matrix.python-version }}\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: ${{ matrix.python-version }}\n",
    "          \n",
    "      - name: Install base dependencies\n",
    "        run: |\n",
    "          python -m pip install --upgrade pip\n",
    "          pip install jupyter nbconvert nbval\n",
    "          \n",
    "      - name: Install notebook-specific requirements\n",
    "        run: |\n",
    "          if [ -f \"${{ matrix.notebook }}/requirements.txt\" ]; then\n",
    "            echo \"Installing requirements from ${{ matrix.notebook }}/requirements.txt\"\n",
    "            pip install -r \"${{ matrix.notebook }}/requirements.txt\"\n",
    "          else\n",
    "            echo \"No requirements.txt found in ${{ matrix.notebook }}\"\n",
    "            exit 1\n",
    "          fi\n",
    "          \n",
    "      - name: Execute notebook\n",
    "        run: |\n",
    "          cd \"${{ matrix.notebook }}\"\n",
    "          notebook_file=$(find . -name \"*.ipynb\" | head -1)\n",
    "          if [ -n \"$notebook_file\" ]; then\n",
    "            echo \"Executing $notebook_file\"\n",
    "            jupyter nbconvert --to notebook --execute \"$notebook_file\" --output executed_notebook.ipynb\n",
    "          else\n",
    "            echo \"No .ipynb file found in ${{ matrix.notebook }}\"\n",
    "            exit 1\n",
    "          fi\n",
    "          \n",
    "      - name: Validate notebook output\n",
    "        run: |\n",
    "          cd \"${{ matrix.notebook }}\"\n",
    "          if [ -f \"executed_notebook.ipynb\" ]; then\n",
    "            echo \"Notebook executed successfully\"\n",
    "            # Optional: Run nbval for additional validation\n",
    "            pytest --nbval executed_notebook.ipynb || echo \"NBVal validation failed but continuing\"\n",
    "          fi\n",
    "          \n",
    "      - name: Upload executed notebook\n",
    "        uses: actions/upload-artifact@v3\n",
    "        if: always()\n",
    "        with:\n",
    "          name: executed-notebook-${{ matrix.notebook }}-${{ matrix.python-version }}\n",
    "          path: ${{ matrix.notebook }}/executed_notebook.ipynb\n",
    "          retention-days: 30\n",
    "'''\n",
    "\n",
    "print(\"GitHub Actions Workflow for Matrix Execution:\")\n",
    "print(workflow_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f03e05",
   "metadata": {},
   "source": [
    "## 2. Spawn Notebook Runners\n",
    "\n",
    "Each notebook in the matrix runs in its own isolated runner environment. Here's how the spawning process works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7451a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of how GitHub Actions spawns runners for each matrix job\n",
    "\n",
    "def simulate_runner_spawning(matrix_config):\n",
    "    \"\"\"\n",
    "    Simulate how GitHub Actions spawns individual runners for each matrix combination\n",
    "    \"\"\"\n",
    "    runners = []\n",
    "    \n",
    "    for notebook in matrix_config['strategy']['matrix']['notebook']:\n",
    "        for python_version in matrix_config['strategy']['matrix']['python-version']:\n",
    "            for os in matrix_config['strategy']['matrix']['os']:\n",
    "                runner = {\n",
    "                    'id': f\"runner-{len(runners)+1}\",\n",
    "                    'notebook': notebook,\n",
    "                    'python_version': python_version,\n",
    "                    'os': os,\n",
    "                    'status': 'spawned',\n",
    "                    'isolated_env': True\n",
    "                }\n",
    "                runners.append(runner)\n",
    "    \n",
    "    return runners\n",
    "\n",
    "# Simulate spawning runners\n",
    "spawned_runners = simulate_runner_spawning(matrix_config)\n",
    "\n",
    "print(f\"Spawned {len(spawned_runners)} runners:\")\n",
    "for i, runner in enumerate(spawned_runners, 1):\n",
    "    print(f\"{i}. Runner {runner['id']}: {runner['notebook']} (Python {runner['python_version']}, {runner['os']})\")\n",
    "\n",
    "# Show the key benefits\n",
    "print(\"\\n🎯 Benefits of Individual Runners:\")\n",
    "print(\"✅ Complete isolation between notebooks\")\n",
    "print(\"✅ Parallel execution for faster CI/CD\")\n",
    "print(\"✅ Independent failure handling\")\n",
    "print(\"✅ Custom environment per notebook\")\n",
    "print(\"✅ Resource optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86adc42",
   "metadata": {},
   "source": [
    "## 3. Install Requirements\n",
    "\n",
    "Each runner installs only the specific dependencies needed for its notebook. This approach provides:\n",
    "\n",
    "- **Minimal Dependencies**: Only install what's needed\n",
    "- **Version Isolation**: Different notebooks can use different package versions\n",
    "- **Faster Installation**: Smaller requirement sets install faster\n",
    "- **Reduced Conflicts**: No dependency conflicts between notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70404d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example requirements.txt files for different notebook types\n",
    "\n",
    "requirements_examples = {\n",
    "    \"notebooks/data-analysis\": [\n",
    "        \"pandas==2.0.3\",\n",
    "        \"numpy==1.24.3\", \n",
    "        \"matplotlib==3.7.1\",\n",
    "        \"seaborn==0.12.2\",\n",
    "        \"scipy==1.11.1\"\n",
    "    ],\n",
    "    \n",
    "    \"notebooks/visualization\": [\n",
    "        \"plotly==5.15.0\",\n",
    "        \"bokeh==3.2.1\",\n",
    "        \"altair==5.0.1\",\n",
    "        \"pandas==2.0.3\"\n",
    "    ],\n",
    "    \n",
    "    \"notebooks/machine-learning\": [\n",
    "        \"scikit-learn==1.3.0\",\n",
    "        \"tensorflow==2.13.0\",\n",
    "        \"keras==2.13.1\",\n",
    "        \"numpy==1.24.3\",\n",
    "        \"pandas==2.0.3\",\n",
    "        \"joblib==1.3.1\"\n",
    "    ],\n",
    "    \n",
    "    \"notebooks/astronomy\": [\n",
    "        \"astropy==5.3.1\",\n",
    "        \"jwst==1.11.4\",\n",
    "        \"crds==11.16.14\",\n",
    "        \"numpy==1.24.3\",\n",
    "        \"matplotlib==3.7.1\",\n",
    "        \"photutils==1.8.0\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def simulate_requirements_installation(notebook_path, requirements):\n",
    "    \"\"\"\n",
    "    Simulate the requirements installation process for a specific notebook\n",
    "    \"\"\"\n",
    "    print(f\"📦 Installing requirements for {notebook_path}:\")\n",
    "    print(f\"   Found {len(requirements)} packages to install\")\n",
    "    \n",
    "    for req in requirements:\n",
    "        print(f\"   ✅ Installing {req}\")\n",
    "    \n",
    "    print(f\"   🎉 All requirements installed successfully!\\n\")\n",
    "    \n",
    "    return {\n",
    "        'notebook': notebook_path,\n",
    "        'packages_installed': len(requirements),\n",
    "        'status': 'success'\n",
    "    }\n",
    "\n",
    "# Simulate installation for each notebook\n",
    "installation_results = []\n",
    "for notebook_path, requirements in requirements_examples.items():\n",
    "    result = simulate_requirements_installation(notebook_path, requirements)\n",
    "    installation_results.append(result)\n",
    "\n",
    "# Summary\n",
    "print(\"📊 Installation Summary:\")\n",
    "total_packages = sum(r['packages_installed'] for r in installation_results)\n",
    "print(f\"Total notebooks: {len(installation_results)}\")\n",
    "print(f\"Total packages installed: {total_packages}\")\n",
    "print(f\"Average packages per notebook: {total_packages / len(installation_results):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5e0b7",
   "metadata": {},
   "source": [
    "### Advanced Installation Strategies\n",
    "\n",
    "For production environments, consider these optimization strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a369cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced installation strategies for production\n",
    "\n",
    "advanced_strategies = {\n",
    "    \"caching\": {\n",
    "        \"description\": \"Cache dependencies to speed up subsequent runs\",\n",
    "        \"implementation\": \"\"\"\n",
    "- name: Cache pip dependencies\n",
    "  uses: actions/cache@v3\n",
    "  with:\n",
    "    path: ~/.cache/pip\n",
    "    key: ${{ runner.os }}-pip-${{ matrix.notebook }}-${{ hashFiles(format('{0}/requirements.txt', matrix.notebook)) }}\n",
    "    restore-keys: |\n",
    "      ${{ runner.os }}-pip-${{ matrix.notebook }}-\n",
    "      ${{ runner.os }}-pip-\n",
    "\"\"\",\n",
    "        \"benefits\": [\"Faster installation\", \"Reduced network usage\", \"More reliable builds\"]\n",
    "    },\n",
    "    \n",
    "    \"layered_requirements\": {\n",
    "        \"description\": \"Use base + specific requirements for common dependencies\", \n",
    "        \"implementation\": \"\"\"\n",
    "# Base requirements.txt (common packages)\n",
    "base_requirements.txt:\n",
    "  - numpy>=1.24.0\n",
    "  - pandas>=2.0.0\n",
    "  - matplotlib>=3.7.0\n",
    "  \n",
    "# Notebook-specific requirements.txt\n",
    "notebooks/astronomy/requirements.txt:\n",
    "  -r ../../base_requirements.txt\n",
    "  - astropy==5.3.1\n",
    "  - jwst==1.11.4\n",
    "\"\"\",\n",
    "        \"benefits\": [\"Consistent base versions\", \"Reduced duplication\", \"Easier maintenance\"]\n",
    "    },\n",
    "    \n",
    "    \"conditional_installation\": {\n",
    "        \"description\": \"Install different packages based on runner OS or Python version\",\n",
    "        \"implementation\": \"\"\"\n",
    "- name: Install OS-specific requirements\n",
    "  run: |\n",
    "    if [ \"${{ runner.os }}\" = \"macOS\" ]; then\n",
    "      pip install -r ${{ matrix.notebook }}/requirements-macos.txt\n",
    "    else\n",
    "      pip install -r ${{ matrix.notebook }}/requirements.txt\n",
    "    fi\n",
    "\"\"\",\n",
    "        \"benefits\": [\"OS optimization\", \"Conditional dependencies\", \"Platform flexibility\"]\n",
    "    },\n",
    "    \n",
    "    \"timeout_handling\": {\n",
    "        \"description\": \"Add timeouts and retry logic for reliable installation\",\n",
    "        \"implementation\": \"\"\"\n",
    "- name: Install requirements with timeout\n",
    "  run: |\n",
    "    timeout 1200 pip install -r ${{ matrix.notebook }}/requirements.txt || {\n",
    "      echo \"Installation timed out, retrying with --no-cache-dir\"\n",
    "      timeout 1200 pip install --no-cache-dir -r ${{ matrix.notebook }}/requirements.txt\n",
    "    }\n",
    "\"\"\",\n",
    "        \"benefits\": [\"Handles hanging installs\", \"Automatic retry\", \"Better reliability\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"🚀 Advanced Installation Strategies:\")\n",
    "for strategy, details in advanced_strategies.items():\n",
    "    print(f\"\\n📋 {strategy.replace('_', ' ').title()}:\")\n",
    "    print(f\"   {details['description']}\")\n",
    "    print(f\"   Benefits: {', '.join(details['benefits'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced0b8b",
   "metadata": {},
   "source": [
    "## 4. Execute Notebooks\n",
    "\n",
    "Once dependencies are installed, each runner executes its assigned notebook independently. The execution process includes validation, error handling, and artifact collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook execution simulation\n",
    "\n",
    "def simulate_notebook_execution(notebook_path, runner_id):\n",
    "    \"\"\"\n",
    "    Simulate the execution of a notebook in its dedicated runner\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    print(f\"🚀 Runner {runner_id}: Starting execution of {notebook_path}\")\n",
    "    \n",
    "    # Simulate notebook execution steps\n",
    "    steps = [\n",
    "        \"Setting up environment variables\",\n",
    "        \"Loading notebook file\", \n",
    "        \"Validating notebook structure\",\n",
    "        \"Executing cells sequentially\",\n",
    "        \"Capturing outputs and errors\",\n",
    "        \"Generating execution report\",\n",
    "        \"Saving executed notebook\"\n",
    "    ]\n",
    "    \n",
    "    execution_time = 0\n",
    "    for i, step in enumerate(steps, 1):\n",
    "        step_time = random.uniform(2, 8)  # Simulate variable execution time\n",
    "        print(f\"   Step {i}/{len(steps)}: {step} ({step_time:.1f}s)\")\n",
    "        execution_time += step_time\n",
    "        time.sleep(0.1)  # Brief pause for demo\n",
    "    \n",
    "    # Simulate success/failure (90% success rate)\n",
    "    success = random.random() > 0.1\n",
    "    \n",
    "    result = {\n",
    "        'runner_id': runner_id,\n",
    "        'notebook': notebook_path,\n",
    "        'execution_time': round(execution_time, 1),\n",
    "        'status': 'success' if success else 'failed',\n",
    "        'cells_executed': random.randint(8, 25),\n",
    "        'outputs_generated': random.randint(3, 12)\n",
    "    }\n",
    "    \n",
    "    if success:\n",
    "        print(f\"   ✅ Execution completed successfully in {execution_time:.1f}s\")\n",
    "    else:\n",
    "        print(f\"   ❌ Execution failed after {execution_time:.1f}s\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Simulate execution for all spawned runners\n",
    "print(\"📊 Executing notebooks in parallel runners:\\n\")\n",
    "execution_results = []\n",
    "\n",
    "for runner in spawned_runners:\n",
    "    result = simulate_notebook_execution(runner['notebook'], runner['id'])\n",
    "    execution_results.append(result)\n",
    "    print()  # Add spacing between executions\n",
    "\n",
    "# Execution summary\n",
    "successful = [r for r in execution_results if r['status'] == 'success']\n",
    "failed = [r for r in execution_results if r['status'] == 'failed']\n",
    "\n",
    "print(\"\\n📈 Execution Summary:\")\n",
    "print(f\"Total notebooks: {len(execution_results)}\")\n",
    "print(f\"Successful: {len(successful)} ({len(successful)/len(execution_results)*100:.1f}%)\")\n",
    "print(f\"Failed: {len(failed)} ({len(failed)/len(execution_results)*100:.1f}%)\")\n",
    "print(f\"Average execution time: {sum(r['execution_time'] for r in execution_results)/len(execution_results):.1f}s\")\n",
    "print(f\"Total cells executed: {sum(r['cells_executed'] for r in execution_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeedc3c",
   "metadata": {},
   "source": [
    "### Execution Monitoring & Error Handling\n",
    "\n",
    "Production notebook execution requires robust monitoring and error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production-grade execution monitoring\n",
    "\n",
    "monitoring_strategies = {\n",
    "    \"timeout_management\": {\n",
    "        \"description\": \"Prevent notebooks from running indefinitely\",\n",
    "        \"code\": \"\"\"\n",
    "- name: Execute notebook with timeout\n",
    "  run: |\n",
    "    cd \"${{ matrix.notebook }}\"\n",
    "    timeout 1800 jupyter nbconvert --to notebook --execute *.ipynb \\\n",
    "      --ExecutePreprocessor.timeout=300 \\\n",
    "      --ExecutePreprocessor.kernel_name=python3 \\\n",
    "      --output executed_notebook.ipynb\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"memory_monitoring\": {\n",
    "        \"description\": \"Monitor memory usage during execution\",\n",
    "        \"code\": \"\"\"\n",
    "- name: Monitor memory usage\n",
    "  run: |\n",
    "    # Start memory monitoring in background\n",
    "    (while true; do \n",
    "      echo \"$(date): Memory: $(free -h | grep Mem | awk '{print $3}')\" \n",
    "      sleep 30\n",
    "    done) &\n",
    "    MONITOR_PID=$!\n",
    "    \n",
    "    # Execute notebook\n",
    "    jupyter nbconvert --execute *.ipynb\n",
    "    \n",
    "    # Stop monitoring\n",
    "    kill $MONITOR_PID\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"error_collection\": {\n",
    "        \"description\": \"Collect detailed error information for debugging\",\n",
    "        \"code\": \"\"\"\n",
    "- name: Execute with error collection\n",
    "  run: |\n",
    "    set +e  # Don't exit on error\n",
    "    jupyter nbconvert --execute *.ipynb --to notebook \\\n",
    "      --output executed_notebook.ipynb \\\n",
    "      --ExecutePreprocessor.allow_errors=True 2> execution_errors.log\n",
    "    \n",
    "    if [ $? -ne 0 ]; then\n",
    "      echo \"Notebook execution failed, collecting debug info\"\n",
    "      echo \"=== Error Log ===\" >> debug_info.txt\n",
    "      cat execution_errors.log >> debug_info.txt\n",
    "      echo \"=== Environment Info ===\" >> debug_info.txt\n",
    "      pip list >> debug_info.txt\n",
    "      echo \"=== System Info ===\" >> debug_info.txt\n",
    "      uname -a >> debug_info.txt\n",
    "    fi\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"artifact_management\": {\n",
    "        \"description\": \"Save execution artifacts for analysis\",\n",
    "        \"code\": \"\"\"\n",
    "- name: Upload execution artifacts\n",
    "  uses: actions/upload-artifact@v3\n",
    "  if: always()\n",
    "  with:\n",
    "    name: notebook-execution-${{ matrix.notebook }}\n",
    "    path: |\n",
    "      ${{ matrix.notebook }}/executed_notebook.ipynb\n",
    "      ${{ matrix.notebook }}/execution_errors.log\n",
    "      ${{ matrix.notebook }}/debug_info.txt\n",
    "      ${{ matrix.notebook }}/**/*.png\n",
    "      ${{ matrix.notebook }}/**/*.html\n",
    "    retention-days: 30\n",
    "\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"🔍 Production Monitoring Strategies:\")\n",
    "for strategy, details in monitoring_strategies.items():\n",
    "    print(f\"\\n📋 {strategy.replace('_', ' ').title()}:\")\n",
    "    print(f\"   {details['description']}\")\n",
    "    \n",
    "# Show execution metrics\n",
    "print(\"\\n📊 Key Execution Metrics to Track:\")\n",
    "metrics = [\n",
    "    \"Execution time per notebook\",\n",
    "    \"Memory usage peaks\", \n",
    "    \"Cell-by-cell execution status\",\n",
    "    \"Error types and frequencies\",\n",
    "    \"Success/failure rates\",\n",
    "    \"Resource utilization\",\n",
    "    \"Artifact sizes\"\n",
    "]\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    print(f\"{i}. {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103a0eb",
   "metadata": {},
   "source": [
    "## 🚀 Production Optimization & Best Practices\n",
    "\n",
    "Matrix-based execution enables powerful optimizations for large-scale notebook operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97862f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production optimization strategies\n",
    "\n",
    "optimizations = {\n",
    "    \"dynamic_matrix_generation\": {\n",
    "        \"description\": \"Generate matrix based on changed files\",\n",
    "        \"benefit\": \"Only test affected notebooks\",\n",
    "        \"code\": \"\"\"\n",
    "- name: Generate dynamic matrix\n",
    "  id: matrix\n",
    "  run: |\n",
    "    # Get changed notebook directories\n",
    "    if [ \"${{ github.event_name }}\" = \"pull_request\" ]; then\n",
    "      changed_notebooks=$(git diff --name-only HEAD^ HEAD | \\\n",
    "        grep '\\.ipynb$' | xargs dirname | sort -u)\n",
    "    else\n",
    "      # For push events, test all notebooks\n",
    "      changed_notebooks=$(find notebooks -name '*.ipynb' -exec dirname {} \\; | sort -u)\n",
    "    fi\n",
    "    \n",
    "    # Convert to JSON matrix\n",
    "    matrix=$(echo \"$changed_notebooks\" | jq -R -s -c \\\n",
    "      'split(\"\\n\")[:-1] | {\"notebook\": .}')\n",
    "    echo \"matrix=$matrix\" >> $GITHUB_OUTPUT\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"runner_type_optimization\": {\n",
    "        \"description\": \"Use different runner types based on notebook requirements\",\n",
    "        \"benefit\": \"Cost optimization and performance tuning\",\n",
    "        \"code\": \"\"\"\n",
    "strategy:\n",
    "  matrix:\n",
    "    include:\n",
    "      # Lightweight notebooks - standard runners\n",
    "      - notebook: notebooks/simple-analysis\n",
    "        os: ubuntu-latest\n",
    "        runner-type: standard\n",
    "      \n",
    "      # Heavy computation - larger runners  \n",
    "      - notebook: notebooks/machine-learning\n",
    "        os: ubuntu-latest-4-cores\n",
    "        runner-type: large\n",
    "      \n",
    "      # GPU workloads - GPU runners\n",
    "      - notebook: notebooks/deep-learning  \n",
    "        os: ubuntu-latest-gpu\n",
    "        runner-type: gpu\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"conditional_execution\": {\n",
    "        \"description\": \"Skip execution based on conditions\",\n",
    "        \"benefit\": \"Reduce unnecessary runs\",\n",
    "        \"code\": \"\"\"\n",
    "- name: Check if execution needed\n",
    "  id: check\n",
    "  run: |\n",
    "    # Skip if only documentation changed\n",
    "    if git diff --name-only HEAD^ HEAD | grep -E '\\.(md|rst|txt)$' && \\\n",
    "       ! git diff --name-only HEAD^ HEAD | grep -E '\\.(ipynb|py)$'; then\n",
    "      echo \"skip=true\" >> $GITHUB_OUTPUT\n",
    "    else\n",
    "      echo \"skip=false\" >> $GITHUB_OUTPUT  \n",
    "    fi\n",
    "    \n",
    "- name: Execute notebook\n",
    "  if: steps.check.outputs.skip == 'false'\n",
    "  run: jupyter nbconvert --execute *.ipynb\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"parallel_artifact_processing\": {\n",
    "        \"description\": \"Process artifacts in parallel after execution\",\n",
    "        \"benefit\": \"Faster CI completion\",\n",
    "        \"code\": \"\"\"\n",
    "  # Separate job for artifact processing\n",
    "  process-artifacts:\n",
    "    needs: execute-notebooks\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - name: Download all artifacts\n",
    "        uses: actions/download-artifact@v3\n",
    "        \n",
    "      - name: Process in parallel\n",
    "        run: |\n",
    "          # Process multiple artifacts simultaneously\n",
    "          for dir in artifact-*/; do\n",
    "            (cd \"$dir\" && process_notebook_output.py) &\n",
    "          done\n",
    "          wait  # Wait for all background processes\n",
    "\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"⚡ Production Optimization Strategies:\")\n",
    "for opt, details in optimizations.items():\n",
    "    print(f\"\\n🎯 {opt.replace('_', ' ').title()}:\")\n",
    "    print(f\"   {details['description']}\")\n",
    "    print(f\"   Benefit: {details['benefit']}\")\n",
    "\n",
    "# Show resource optimization calculations\n",
    "print(\"\\n💰 Resource Optimization Example:\")\n",
    "print(\"Traditional approach (sequential):\")\n",
    "print(\"  - 10 notebooks × 15 minutes each = 150 minutes\")\n",
    "print(\"  - 1 runner for 150 minutes = 150 runner-minutes\")\n",
    "print()\n",
    "print(\"Matrix approach (parallel):\")\n",
    "print(\"  - 10 notebooks × 15 minutes each in parallel = 15 minutes\")\n",
    "print(\"  - 10 runners for 15 minutes = 150 runner-minutes\")\n",
    "print(\"  - 🎉 90% time reduction (150min → 15min)\")\n",
    "print(\"  - Same cost, dramatically faster feedback!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf49ab",
   "metadata": {},
   "source": [
    "## 🔧 Troubleshooting & Maintenance\n",
    "\n",
    "Common issues and solutions for matrix-based notebook execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common troubleshooting scenarios\n",
    "\n",
    "troubleshooting_guide = {\n",
    "    \"matrix_generation_failures\": {\n",
    "        \"symptom\": \"Matrix job shows empty or invalid matrix\",\n",
    "        \"causes\": [\n",
    "            \"No notebooks found in expected directories\",\n",
    "            \"Invalid JSON generation in matrix step\",\n",
    "            \"File path issues with spaces or special characters\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"Add debug output to matrix generation step\",\n",
    "            \"Validate JSON before setting output\",\n",
    "            \"Use proper escaping for file paths\"\n",
    "        ],\n",
    "        \"debug_code\": \"\"\"\n",
    "- name: Debug matrix generation\n",
    "  run: |\n",
    "    echo \"Found notebooks:\"\n",
    "    find notebooks -name '*.ipynb' | head -10\n",
    "    echo \"Generated matrix:\"\n",
    "    echo \"$matrix\" | jq .\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"dependency_conflicts\": {\n",
    "        \"symptom\": \"Package installation fails with dependency conflicts\",\n",
    "        \"causes\": [\n",
    "            \"Conflicting version requirements\",\n",
    "            \"Platform-specific package issues\",\n",
    "            \"Outdated requirements.txt files\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"Use pip-tools for dependency resolution\",\n",
    "            \"Pin specific package versions\",\n",
    "            \"Regular dependency updates\"\n",
    "        ],\n",
    "        \"debug_code\": \"\"\"\n",
    "- name: Debug dependency issues\n",
    "  run: |\n",
    "    echo \"Python version: $(python --version)\"\n",
    "    echo \"Pip version: $(pip --version)\"\n",
    "    echo \"Requirements content:\"\n",
    "    cat ${{ matrix.notebook }}/requirements.txt\n",
    "    echo \"Attempting installation with verbose output:\"\n",
    "    pip install -v -r ${{ matrix.notebook }}/requirements.txt\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"notebook_execution_failures\": {\n",
    "        \"symptom\": \"Notebooks fail during execution\",\n",
    "        \"causes\": [\n",
    "            \"Runtime errors in notebook cells\",\n",
    "            \"Missing data files or resources\",\n",
    "            \"Memory or timeout issues\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"Use ExecutePreprocessor.allow_errors=True for testing\",\n",
    "            \"Implement proper error handling in notebooks\",\n",
    "            \"Increase timeout values for long-running cells\"\n",
    "        ],\n",
    "        \"debug_code\": \"\"\"\n",
    "- name: Debug notebook execution\n",
    "  run: |\n",
    "    cd \"${{ matrix.notebook }}\"\n",
    "    echo \"Notebook content summary:\"\n",
    "    jupyter nbconvert --to python *.ipynb --stdout | head -50\n",
    "    echo \"Available files:\"\n",
    "    ls -la\n",
    "    echo \"Memory before execution:\"\n",
    "    free -h\n",
    "\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"runner_capacity_issues\": {\n",
    "        \"symptom\": \"Jobs queued for long periods or runners out of capacity\",\n",
    "        \"causes\": [\n",
    "            \"Too many parallel jobs\",\n",
    "            \"Insufficient runner quota\",\n",
    "            \"Long-running notebooks blocking resources\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"Implement job concurrency limits\",\n",
    "            \"Use conditional execution\",\n",
    "            \"Optimize notebook execution time\"\n",
    "        ],\n",
    "        \"debug_code\": \"\"\"\n",
    "# Add concurrency control\n",
    "concurrency:\n",
    "  group: notebook-ci-${{ github.ref }}\n",
    "  cancel-in-progress: true\n",
    "  \n",
    "# Or limit parallel jobs\n",
    "strategy:\n",
    "  max-parallel: 5  # Limit concurrent executions\n",
    "\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"🛠️ Troubleshooting Guide:\")\n",
    "for issue, details in troubleshooting_guide.items():\n",
    "    print(f\"\\n❌ {issue.replace('_', ' ').title()}:\")\n",
    "    print(f\"   Symptom: {details['symptom']}\")\n",
    "    print(f\"   Common causes: {len(details['causes'])} identified\")\n",
    "    print(f\"   Available solutions: {len(details['solutions'])} strategies\")\n",
    "\n",
    "# Maintenance checklist\n",
    "print(\"\\n📋 Regular Maintenance Checklist:\")\n",
    "maintenance_tasks = [\n",
    "    \"Update requirements.txt files monthly\",\n",
    "    \"Review and optimize slow-running notebooks\",\n",
    "    \"Monitor runner usage and costs\",\n",
    "    \"Update base Docker images\",\n",
    "    \"Check for deprecated GitHub Actions\",\n",
    "    \"Review artifact retention policies\",\n",
    "    \"Update timeout values based on execution patterns\",\n",
    "    \"Clean up old workflow runs and artifacts\"\n",
    "]\n",
    "\n",
    "for i, task in enumerate(maintenance_tasks, 1):\n",
    "    print(f\"{i}. {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ccbfe",
   "metadata": {},
   "source": [
    "## 🎯 Conclusion & Next Steps\n",
    "\n",
    "Matrix-based notebook execution provides a robust, scalable solution for production Jupyter notebook CI/CD. This approach offers:\n",
    "\n",
    "### ✅ **Key Benefits Achieved**\n",
    "\n",
    "- **🚀 Parallel Execution**: 90% faster CI completion\n",
    "- **🔒 Isolation**: Each notebook runs independently\n",
    "- **📦 Dependency Management**: Notebook-specific requirements\n",
    "- **💰 Cost Optimization**: Efficient resource usage\n",
    "- **🛡️ Fault Tolerance**: Individual failure containment\n",
    "- **📊 Scalability**: Linear scaling with notebook count\n",
    "\n",
    "### 🔄 **Implementation Path**\n",
    "\n",
    "1. **Start Small**: Begin with 2-3 notebooks\n",
    "2. **Optimize**: Add caching and conditional execution\n",
    "3. **Scale**: Gradually add more notebooks to matrix\n",
    "4. **Monitor**: Implement comprehensive logging and metrics\n",
    "5. **Maintain**: Regular dependency and workflow updates\n",
    "\n",
    "### 🚀 **Advanced Features to Explore**\n",
    "\n",
    "- **Dynamic resource allocation** based on notebook complexity\n",
    "- **Intelligent change detection** for selective execution\n",
    "- **Multi-environment testing** (dev/staging/prod)\n",
    "- **Automated dependency updates** with compatibility testing\n",
    "- **Performance regression detection** with historical baselines\n",
    "\n",
    "### 📚 **Additional Resources**\n",
    "\n",
    "- [GitHub Actions Matrix Documentation](https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstrategymatrix)\n",
    "- [Jupyter nbconvert Documentation](https://nbconvert.readthedocs.io/)\n",
    "- [Production Notebook Best Practices](../docs/local-testing-guide.md)\n",
    "- [Example Workflows](../examples/workflows/)\n",
    "\n",
    "This matrix-based approach transforms notebook CI/CD from a bottleneck into a competitive advantage! 🎉"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
