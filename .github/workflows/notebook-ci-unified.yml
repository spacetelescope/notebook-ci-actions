name: Unified Notebook CI/CD Pipeline

on:
  workflow_call:
    inputs:
      # Execution Configuration
      execution-mode:
        description: 'Execution mode: pr, merge, scheduled, on-demand'
        required: true
        type: string
      trigger-event:
        description: 'Specific trigger: validate, execute, security, html, deprecate'
        required: false
        type: string
        default: 'all'
      
      # Environment Configuration
      python-version:
        description: 'Python version to use'
        required: false
        type: string
        default: '3.11'
      conda-environment:
        description: 'Custom conda environment (hstcal, stenv, etc.)'
        required: false
        type: string
      custom-requirements:
        description: 'Path to custom requirements file'
        required: false
        type: string
      
      # Notebook Selection
      single-notebook:
        description: 'Single notebook path for targeted execution'
        required: false
        type: string
      affected-directories:
        description: 'JSON array of affected directories (auto-detected or manual)'
        required: false
        type: string
        default: '[]'
      
      # Feature Flags
      enable-validation:
        description: 'Enable pytest nbval validation'
        required: false
        type: boolean
        default: true
      enable-security:
        description: 'Enable bandit security testing'
        required: false
        type: boolean
        default: true
      enable-execution:
        description: 'Enable notebook execution'
        required: false
        type: boolean
        default: true
      enable-storage:
        description: 'Enable storing outputs to gh-storage'
        required: false
        type: boolean
        default: true
      enable-html-build:
        description: 'Enable HTML documentation build'
        required: false
        type: boolean
        default: false
      
      # Post-processing
      post-processing-script:
        description: 'Optional post-processing script path'
        required: false
        type: string
      
      # Deprecation
      deprecation-days:
        description: 'Days until deprecation (default: 60)'
        required: false
        type: number
        default: 60

    secrets:
      CASJOBS_USERID:
        required: false
      CASJOBS_PW:
        required: false

jobs:
  # Change Detection and Matrix Setup
  setup-matrix:
    runs-on: ubuntu-24.04
    outputs:
      matrix-notebooks: ${{ steps.setup.outputs.matrix-notebooks }}
      affected-dirs: ${{ steps.setup.outputs.affected-dirs }}
      skip-execution: ${{ steps.setup.outputs.skip-execution }}
      docs-only: ${{ steps.setup.outputs.docs-only }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup matrix and detect changes
        id: setup
        run: |
          # Initialize variables
          SKIP_EXECUTION=false
          DOCS_ONLY=false
          MATRIX_NOTEBOOKS="[]"
          AFFECTED_DIRS="${{ inputs.affected-directories }}"
          
          case "${{ inputs.execution-mode }}" in
            "pr")
              echo "🔄 PR Mode: Detecting changed files"
              if [ "$GITHUB_EVENT_NAME" = "pull_request" ]; then
                BASE_REF=$(jq -r .pull_request.base.ref < "$GITHUB_EVENT_PATH")
                git fetch origin "$BASE_REF"
                CHANGED_FILES=$(git diff --name-only origin/$BASE_REF...HEAD)
              else
                CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
              fi
              
              # Detect docs-only changes
              DOCS_ONLY=true
              NOTEBOOKS_CHANGED=false
              declare -a CHANGED_NOTEBOOKS
              declare -a AFFECTED_DIRECTORIES
              
              while IFS= read -r file; do
                [[ -z "$file" ]] && continue
                case "$file" in
                  notebooks/*.ipynb)
                    NOTEBOOKS_CHANGED=true
                    DOCS_ONLY=false
                    CHANGED_NOTEBOOKS+=("$file")
                    dir=$(dirname "$file")
                    if [[ ! " ${AFFECTED_DIRECTORIES[*]} " =~ " $dir " ]]; then
                      AFFECTED_DIRECTORIES+=("$dir")
                    fi
                    ;;
                  notebooks/*/requirements.txt|requirements.txt|pyproject.toml)
                    NOTEBOOKS_CHANGED=true
                    DOCS_ONLY=false
                    dir=$(dirname "$file")
                    if [[ "$file" == "requirements.txt" || "$file" == "pyproject.toml" ]]; then
                      AFFECTED_DIRECTORIES=("notebooks")
                    elif [[ ! " ${AFFECTED_DIRECTORIES[*]} " =~ " $dir " ]]; then
                      AFFECTED_DIRECTORIES+=("$dir")
                    fi
                    ;;
                  *.md|*.html|*.css|*.js|_config.yml|_toc.yml)
                    # Keep DOCS_ONLY=true, but enable HTML build
                    ;;
                  *)
                    DOCS_ONLY=false
                    ;;
                esac
              done <<< "$CHANGED_FILES"
              
              if [ "$DOCS_ONLY" = "true" ]; then
                echo "📚 Docs-only changes detected"
                SKIP_EXECUTION=true
              elif [ ${#CHANGED_NOTEBOOKS[@]} -gt 0 ]; then
                MATRIX_NOTEBOOKS=$(printf '%s\n' "${CHANGED_NOTEBOOKS[@]}" | jq -R . | jq -s -c .)
                AFFECTED_DIRS=$(printf '%s\n' "${AFFECTED_DIRECTORIES[@]}" | jq -R . | jq -s -c .)
              fi
              ;;
              
            "merge")
              echo "🚀 Merge Mode: Full repository processing"  
              MATRIX_NOTEBOOKS=$(find notebooks/ -name '*.ipynb' | jq -R -s -c 'split("\n")[:-1] | map(select(. != ""))')
              AFFECTED_DIRS='["notebooks"]'
              ;;
              
            "scheduled")
              echo "⏰ Scheduled Mode: All notebooks validation"
              MATRIX_NOTEBOOKS=$(find notebooks/ -name '*.ipynb' | jq -R -s -c 'split("\n")[:-1] | map(select(. != ""))')
              AFFECTED_DIRS='["notebooks"]'
              ;;
              
            "on-demand")
              echo "🎯 On-demand Mode"
              # Check if this is a documentation-only build
              if [ "${{ inputs.trigger-event }}" = "html" ]; then
                echo "📚 Documentation-only build: skipping notebook processing"
                SKIP_EXECUTION=true
                MATRIX_NOTEBOOKS='[]'
                AFFECTED_DIRS='[]'
              elif [ -n "${{ inputs.single-notebook }}" ]; then
                echo "📄 Single notebook specified: ${{ inputs.single-notebook }}"
                
                # Check if it's a full path or just a filename
                if [[ "${{ inputs.single-notebook }}" == *"/"* ]]; then
                  # Full path provided
                  NOTEBOOK_PATH="${{ inputs.single-notebook }}"
                  echo "📁 Full path provided: $NOTEBOOK_PATH"
                else
                  # Just filename provided - find the full path
                  echo "🔍 Filename only provided, searching for: ${{ inputs.single-notebook }}"
                  NOTEBOOK_PATH=$(find notebooks/ -name "${{ inputs.single-notebook }}" -type f | head -1)
                  if [ -z "$NOTEBOOK_PATH" ]; then
                    echo "❌ Notebook not found: ${{ inputs.single-notebook }}"
                    echo "Available notebooks:"
                    find notebooks/ -name '*.ipynb' | head -10
                    exit 1
                  fi
                  echo "✅ Found notebook at: $NOTEBOOK_PATH"
                fi
                
                MATRIX_NOTEBOOKS=$(echo "$NOTEBOOK_PATH" | jq -R -s -c 'split("\n")[:-1]')
                # Calculate the directory for the single notebook
                SINGLE_NOTEBOOK_DIR=$(dirname "$NOTEBOOK_PATH")
                AFFECTED_DIRS=$(echo "$SINGLE_NOTEBOOK_DIR" | jq -R -s -c 'split("\n")[:-1]')
                echo "📁 Calculated directory: $SINGLE_NOTEBOOK_DIR"
              else
                MATRIX_NOTEBOOKS=$(find notebooks/ -name '*.ipynb' | jq -R -s -c 'split("\n")[:-1] | map(select(. != ""))')
                AFFECTED_DIRS='["notebooks"]'
              fi
              ;;
          esac
          
          echo "matrix-notebooks=$MATRIX_NOTEBOOKS" >> $GITHUB_OUTPUT
          echo "affected-dirs=$AFFECTED_DIRS" >> $GITHUB_OUTPUT  
          echo "skip-execution=$SKIP_EXECUTION" >> $GITHUB_OUTPUT
          echo "docs-only=$DOCS_ONLY" >> $GITHUB_OUTPUT
          
          echo "📊 Matrix Setup Complete:"
          echo "  Notebooks: $MATRIX_NOTEBOOKS"
          echo "  Affected Dirs: $AFFECTED_DIRS"
          echo "  Skip Execution: $SKIP_EXECUTION"
          echo "  Docs Only: $DOCS_ONLY"

  # Main Notebook Processing
  process-notebooks:
    needs: setup-matrix
    if: |
      needs.setup-matrix.outputs.skip-execution != 'true' && 
      needs.setup-matrix.outputs.matrix-notebooks != '[]' &&
      inputs.execution-mode != 'merge'
    runs-on: ubuntu-24.04
    outputs:
      execution-results: ${{ steps.collect-results.outputs.results }}
      total-notebooks: ${{ steps.collect-results.outputs.total }}
      successful-notebooks: ${{ steps.collect-results.outputs.successful }}
      failed-notebooks: ${{ steps.collect-results.outputs.failed }}
    strategy:
      fail-fast: false
      matrix:
        notebook: ${{ fromJson(needs.setup-matrix.outputs.matrix-notebooks) }}
    env:
      CASJOBS_USERID: ${{ secrets.CASJOBS_USERID }}
      CASJOBS_PW: ${{ secrets.CASJOBS_PW }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Check if notebook is deprecated
        id: deprecation-check
        run: |
          notebook="${{ matrix.notebook }}"
          
          # Check for deprecation markers in notebook
          if grep -q "DEPRECATED\|deprecated\|DEPRECATION" "$notebook"; then
            echo "⚠️ Notebook marked as deprecated: $notebook"
            echo "deprecated=true" >> $GITHUB_OUTPUT
          else
            echo "deprecated=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up Python environment with micromamba
        uses: mamba-org/setup-micromamba@v2.0.4
        with:
          environment-name: ci-env
          init-shell: bash
          create-args: "python=${{ inputs.python-version }} pip jupyter nbval nbconvert bandit pytest"
          cache-environment: true

      - name: Set up custom conda environment
        if: inputs.conda-environment != ''
        run: |
          echo "🔧 Setting up custom conda environment: ${{ inputs.conda-environment }}"
          # Create environment with specified conda environment packages
          micromamba install -n ci-env ${{ inputs.conda-environment }} -y

      - name: Install requirements
        run: |
          notebook="${{ matrix.notebook }}"
          nb_dir=$(dirname "$notebook")
          
          # Activate the micromamba environment
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          
          # Install custom requirements if specified
          if [ -n "${{ inputs.custom-requirements }}" ]; then
            echo "Installing custom requirements: ${{ inputs.custom-requirements }}"
            pip install -r "${{ inputs.custom-requirements }}"
          elif [ -f "$nb_dir/requirements.txt" ]; then
            echo "Installing directory-specific requirements: $nb_dir/requirements.txt"
            pip install -r "$nb_dir/requirements.txt"
          else
            echo "No requirements.txt found in $nb_dir - using base environment only"
          fi

      - name: Validate notebook
        if: inputs.enable-validation == true && (inputs.trigger-event == 'all' || inputs.trigger-event == 'validate')
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          echo "🔍 Validating notebook: ${{ matrix.notebook }}"
          pytest --nbval --nbval-cell-timeout=4000 "${{ matrix.notebook }}"

      - name: Security scan
        if: inputs.enable-security == true && (inputs.trigger-event == 'all' || inputs.trigger-event == 'security')
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          echo "🛡️ Security scanning: ${{ matrix.notebook }}"
          notebook="${{ matrix.notebook }}"
          jupyter nbconvert --to script "$notebook"
          py_file="${notebook%.ipynb}.py"
          if [ -f "$py_file" ]; then
            bandit "$py_file" || echo "Security warnings found"
            rm -f "$py_file"
          fi

      - name: Execute notebook
        if: inputs.enable-execution == true && (inputs.trigger-event == 'all' || inputs.trigger-event == 'execute')
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          echo "▶️ Executing notebook: ${{ matrix.notebook }}"
          jupyter nbconvert --to notebook --execute --inplace "${{ matrix.notebook }}"

      - name: Store executed notebook to gh-storage
        if: |
          inputs.enable-storage == true && 
          steps.deprecation-check.outputs.deprecated != 'true' &&
          success() && 
          (inputs.execution-mode == 'pr' || inputs.execution-mode == 'merge' || inputs.trigger-event == 'execute')
        run: |
          echo "💾 Storing executed notebook to gh-storage"
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          
          notebook="${{ matrix.notebook }}"
          
          if [ "${{ inputs.execution-mode }}" = "pr" ]; then
            echo "🔄 PR mode: Force-pushing ONLY the executed notebook to gh-storage"
            
            # Store current state
            current_branch=$(git branch --show-current)
            echo "📍 Current branch: $current_branch"
            
            # Create a backup copy of the executed notebook BEFORE any branch operations
            temp_notebook="/tmp/executed_$(basename "$notebook")"
            cp "$notebook" "$temp_notebook"
            echo "📋 Backed up executed notebook to: $temp_notebook"
            
            # Stash the executed notebook changes to allow clean branch switch
            git add "$notebook"
            git stash push -m "Temporary stash of executed notebook for gh-storage" -- "$notebook"
            echo "� Stashed executed notebook changes for clean branch switch"
            
            # Switch to gh-storage branch (create if doesn't exist)
            if git ls-remote --exit-code origin gh-storage >/dev/null 2>&1; then
              echo "📦 Using existing gh-storage branch"
              git fetch origin gh-storage
              git checkout gh-storage
            else
              echo "🆕 Creating new gh-storage branch"
              git checkout --orphan gh-storage
              git rm -rf . >/dev/null 2>&1 || true
            fi
            
            # Create directory structure and copy ONLY the executed notebook from backup
            echo "� Setting up directory: $(dirname "$notebook")"
            mkdir -p "$(dirname "$notebook")"
            cp "$temp_notebook" "$notebook"
            echo "📋 Copied executed notebook from backup: $notebook"
            
            # Stage ONLY this notebook file
            git add "$notebook"
            
            # Check if there are actual changes to commit
            if git diff --cached --quiet; then
              echo "ℹ️ No changes detected in $notebook"
            else
              echo "✅ Changes detected, committing notebook"
              git commit -m "Update executed notebook $notebook from PR #${{ github.event.number }} [skip ci]"
              
              # Force push to ensure clean update without conflicts
              git push --force origin gh-storage
              echo "🚀 Successfully force-pushed $notebook to gh-storage"
            fi
            
            # Clean up backup file and return to original branch
            rm -f "$temp_notebook"
            
            # Return to original branch (handle empty branch name)
            if [ -n "$current_branch" ]; then
              git checkout "$current_branch"
              echo "🔄 Returned to original branch: $current_branch"
            else
              # Fallback to default branch if current_branch is empty
              git checkout "${{ github.ref_name }}" || git checkout main || git checkout master
              echo "🔄 Returned to default branch (current_branch was empty)"
            fi
            
            # Clean up stash if it exists
            if git stash list | grep -q "Temporary stash of executed notebook for gh-storage"; then
              git stash drop
              echo "🧹 Cleaned up temporary stash"
            fi
            
          else
            echo "🔄 Merge/Execute mode: Adding notebook to gh-storage"
            
            # Store current state
            current_branch=$(git branch --show-current)
            echo "📍 Current branch: $current_branch"
            
            # Create a backup copy of the executed notebook BEFORE any branch operations
            temp_notebook="/tmp/executed_$(basename "$notebook")"
            cp "$notebook" "$temp_notebook"
            echo "📋 Backed up executed notebook to: $temp_notebook"
            
            # Stash the executed notebook changes to allow clean branch switch
            git add "$notebook"
            git stash push -m "Temporary stash of executed notebook for gh-storage" -- "$notebook"
            echo "� Stashed executed notebook changes for clean branch switch"
            
            # Switch to gh-storage branch
            if git ls-remote --exit-code origin gh-storage >/dev/null 2>&1; then
              echo "📦 Using existing gh-storage branch"
              git fetch origin gh-storage
              git checkout gh-storage
            else
              echo "🆕 Creating new gh-storage branch"
              git checkout --orphan gh-storage
              git rm -rf . >/dev/null 2>&1 || true
            fi
            
            # Create directory structure and copy the executed notebook from backup
            echo "� Setting up directory: $(dirname "$notebook")"  
            mkdir -p "$(dirname "$notebook")"
            cp "$temp_notebook" "$notebook"
            echo "📋 Copied executed notebook from backup: $notebook"
            
            # Stage and commit the notebook
            git add "$notebook"
            if git diff --cached --quiet; then
              echo "ℹ️ No changes detected in $notebook"
            else
              echo "✅ Changes detected, committing notebook"
              git commit -m "Update executed notebook $notebook [skip ci]"
              
              # Try regular push first, then force if needed
              if git push origin gh-storage; then
                echo "🚀 Successfully pushed $notebook to gh-storage"
              else
                echo "⚠️ Regular push failed, force pushing..."
                git push --force origin gh-storage
                echo "🚀 Force-pushed $notebook to gh-storage"  
              fi
            fi
            
            # Clean up backup file and return to original branch
            rm -f "$temp_notebook"
            
            # Return to original branch (handle empty branch name)
            if [ -n "$current_branch" ]; then
              git checkout "$current_branch"
              echo "🔄 Returned to original branch: $current_branch"
            else
              # Fallback to default branch if current_branch is empty
              git checkout "${{ github.ref_name }}" || git checkout main || git checkout master
              echo "🔄 Returned to default branch (current_branch was empty)"
            fi
            
            # Clean up stash if it exists
            if git stash list | grep -q "Temporary stash of executed notebook for gh-storage"; then
              git stash drop
              echo "🧹 Cleaned up temporary stash"
            fi
          fi

      - name: Record execution result
        if: always()
        run: |
          # Record the result for this notebook
          notebook="${{ matrix.notebook }}"
          result="${{ job.status }}"
          
          echo "📊 Recording result for $notebook: $result"
          
          # Create a results directory if it doesn't exist
          mkdir -p /tmp/notebook-results
          
          # Write result to a file
          echo "$notebook:$result" >> /tmp/notebook-results/execution-results.txt
          
          # Also create individual result files for easier parsing
          if [ "$result" = "success" ]; then
            echo "$notebook" >> /tmp/notebook-results/successful.txt
          else
            echo "$notebook" >> /tmp/notebook-results/failed.txt
          fi

      - name: Collect execution results
        id: collect-results
        if: always()
        run: |
          # This will run after all matrix jobs complete
          # We'll collect results from the artifact system in the summary job instead
          echo "results=pending" >> $GITHUB_OUTPUT
          echo "total=1" >> $GITHUB_OUTPUT
          echo "successful=0" >> $GITHUB_OUTPUT  
          echo "failed=0" >> $GITHUB_OUTPUT

  # HTML Documentation Build
  build-documentation:
    needs: [setup-matrix]
    if: |
      always() && 
      inputs.enable-html-build == true &&
      (needs.setup-matrix.outputs.docs-only == 'true' || 
       inputs.execution-mode == 'merge' ||
       inputs.trigger-event == 'html' ||
       (needs.process-notebooks.result == 'success' && inputs.execution-mode != 'merge'))
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ (inputs.execution-mode == 'merge' || inputs.trigger-event == 'html') && 'gh-storage' || github.ref }}
          fetch-depth: 0
          
      - name: Fetch executed notebooks from gh-storage
        if: inputs.execution-mode == 'merge' || inputs.trigger-event == 'html'
        run: |
          echo "📦 Fetching executed notebooks from gh-storage branch"
          git fetch origin gh-storage
          git checkout gh-storage
          echo "✅ Switched to gh-storage branch with executed notebooks"
          
      - name: Set up Python environment with micromamba
        uses: mamba-org/setup-micromamba@v2.0.4
        with:
          environment-name: docs-env
          init-shell: bash
          create-args: "python=${{ inputs.python-version }} pip jupyter-book sphinx"
          cache-environment: true

      - name: Install documentation dependencies
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate docs-env
          echo "📚 Installing documentation dependencies"
          pip install --upgrade jupyter-book sphinx
          
      - name: Build JupyterBook documentation
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate docs-env
          echo "📖 Building JupyterBook documentation"
          
          # Clean any existing build directory
          rm -rf _build
          
          # Build the documentation (don't specify --path-output to use default _build location)
          jupyter-book build .
          echo "✅ JupyterBook documentation built successfully"
          
      - name: Run post-processing script
        if: inputs.post-processing-script != ''
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate docs-env
          echo "🔧 Running post-processing script: ${{ inputs.post-processing-script }}"
          if [ -f "${{ inputs.post-processing-script }}" ]; then
            chmod +x "${{ inputs.post-processing-script }}"
            "${{ inputs.post-processing-script }}"
            echo "✅ Post-processing completed"
          else
            echo "⚠️ Post-processing script not found: ${{ inputs.post-processing-script }}"
          fi

      - name: Deploy to GitHub Pages
        if: inputs.execution-mode == 'merge' || inputs.trigger-event == 'html'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./_build/html
          cname: ${{ vars.PAGES_CNAME || '' }}
          commit_message: "Deploy documentation from executed notebooks [skip ci]"

  # Deprecation Management
  manage-deprecation:
    needs: setup-matrix
    if: inputs.trigger-event == 'deprecate' || inputs.execution-mode == 'scheduled'
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Tag notebook for deprecation
        if: inputs.trigger-event == 'deprecate' && inputs.single-notebook != ''
        run: |
          notebook="${{ inputs.single-notebook }}"
          deprecation_date=$(date -d "+${{ inputs.deprecation-days }} days" +%Y-%m-%d)
          
          echo "🏷️ Tagging notebook for deprecation: $notebook"
          echo "📅 Deprecation date: $deprecation_date"
          
          # Add deprecation banner to notebook
          python3 << 'EOF'
          import json
          import sys
          from datetime import datetime, timedelta
          
          notebook_path = "${{ inputs.single-notebook }}"
          days = ${{ inputs.deprecation-days }}
          
          with open(notebook_path, 'r') as f:
              nb = json.load(f)
          
          deprecation_date = (datetime.now() + timedelta(days=days)).strftime('%Y-%m-%d')
          
          # Add deprecation cell at the beginning
          deprecation_cell = {
              "cell_type": "markdown",
              "metadata": {
                  "tags": ["deprecated"]
              },
              "source": [
                  f"<div style='background-color: #fff3cd; border: 1px solid #ffeaa7; border-radius: 4px; padding: 15px; margin: 10px 0;'>\n",
                  f"<h3 style='color: #856404; margin-top: 0;'>⚠️ DEPRECATED NOTEBOOK</h3>\n",
                  f"<p style='color: #856404; margin-bottom: 0;'>This notebook is scheduled for deprecation on <strong>{deprecation_date}</strong>. It may be moved to the deprecated branch after this date.</p>\n",
                  f"</div>\n"
              ]
          }
          
          # Insert at the beginning
          nb['cells'].insert(0, deprecation_cell)
          
          with open(notebook_path, 'w') as f:
              json.dump(nb, f, indent=2)
          
          print(f"Added deprecation banner to {notebook_path}")
          EOF
          
          # Commit the changes
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add "$notebook"
          git commit -m "Mark notebook as deprecated: $notebook (expires: $deprecation_date)"
          git push origin main

      - name: Check for expired deprecations
        if: inputs.execution-mode == 'scheduled'
        run: |
          echo "🔍 Checking for expired deprecated notebooks"
          
          # Find deprecated notebooks
          python3 << 'EOF'
          import json
          import os
          import subprocess
          from datetime import datetime
          from pathlib import Path
          
          def check_notebook_deprecation(notebook_path):
              with open(notebook_path, 'r') as f:
                  nb = json.load(f)
              
              for cell in nb['cells']:
                  if cell['cell_type'] == 'markdown' and 'tags' in cell.get('metadata', {}):
                      if 'deprecated' in cell['metadata']['tags']:
                          source = ''.join(cell['source'])
                          # Extract date from deprecation banner
                          import re
                          date_match = re.search(r'(\d{4}-\d{2}-\d{2})', source)
                          if date_match:
                              dep_date = datetime.strptime(date_match.group(1), '%Y-%m-%d')
                              if dep_date <= datetime.now():
                                  return True, dep_date
              return False, None
          
          deprecated_notebooks = []
          
          for notebook in Path('notebooks').rglob('*.ipynb'):
              is_expired, dep_date = check_notebook_deprecation(notebook)
              if is_expired:
                  deprecated_notebooks.append(str(notebook))
                  print(f"Found expired deprecated notebook: {notebook} (expired: {dep_date})")
          
          if deprecated_notebooks:
              # Create deprecated branch if it doesn't exist
              subprocess.run(['git', 'fetch', 'origin', 'deprecated'], capture_output=True)
              result = subprocess.run(['git', 'checkout', 'deprecated'], capture_output=True)
              if result.returncode != 0:
                  subprocess.run(['git', 'checkout', '--orphan', 'deprecated'])
                  subprocess.run(['git', 'rm', '-rf', '.'])
              
              # Copy deprecated notebooks
              subprocess.run(['git', 'checkout', 'main'])
              for notebook in deprecated_notebooks:
                  subprocess.run(['git', 'checkout', 'deprecated'])
                  subprocess.run(['mkdir', '-p', os.path.dirname(notebook)])
                  subprocess.run(['git', 'checkout', 'main', '--', notebook])
                  subprocess.run(['git', 'add', notebook])
              
              # Commit to deprecated branch
              subprocess.run(['git', 'commit', '-m', f'Move {len(deprecated_notebooks)} expired notebooks to deprecated branch'])
              subprocess.run(['git', 'push', 'origin', 'deprecated'])
              
              # Remove from main branch
              subprocess.run(['git', 'checkout', 'main'])
              for notebook in deprecated_notebooks:
                  subprocess.run(['git', 'rm', notebook])
              
              subprocess.run(['git', 'commit', '-m', f'Remove {len(deprecated_notebooks)} deprecated notebooks from main'])
              subprocess.run(['git', 'push', 'origin', 'main'])
              
              print(f"Moved {len(deprecated_notebooks)} notebooks to deprecated branch")
          else:
              print("No expired deprecated notebooks found")
          EOF

  # Summary and Status
  workflow-summary:
    needs: [setup-matrix, process-notebooks, build-documentation, manage-deprecation]
    if: always()
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Generate workflow summary
        run: |
          echo "## 📊 Unified Notebook CI/CD Summary" >> $GITHUB_STEP_SUMMARY
          echo "*Generated: $(date -u +'%Y-%m-%d %H:%M:%S UTC')*" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 🔧 Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Execution Mode**: ${{ inputs.execution-mode }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger Event**: ${{ inputs.trigger-event }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Python Version**: ${{ inputs.python-version }}" >> $GITHUB_STEP_SUMMARY
          if [ -n "${{ inputs.conda-environment }}" ]; then
            echo "- **Custom Conda Environment**: ${{ inputs.conda-environment }}" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -n "${{ inputs.custom-requirements }}" ]; then
            echo "- **Custom Requirements**: ${{ inputs.custom-requirements }}" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -n "${{ inputs.single-notebook }}" ]; then
            echo "- **Single Notebook Target**: \`${{ inputs.single-notebook }}\`" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 📊 Job Results" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status | Duration |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Matrix Setup | ${{ needs.setup-matrix.result }} | - |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.execution-mode }}" != "merge" ]; then
            echo "| Notebook Processing | ${{ needs.process-notebooks.result }} | - |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Notebook Processing | Skipped (merge mode) | - |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Documentation Build | ${{ needs.build-documentation.result }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "| Deprecation Management | ${{ needs.manage-deprecation.result }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 📝 Execution Details" >> $GITHUB_STEP_SUMMARY
          
          # Get the notebooks that were processed
          NOTEBOOKS="${{ needs.setup-matrix.outputs.matrix-notebooks }}"
          AFFECTED_DIRS="${{ needs.setup-matrix.outputs.affected-dirs }}"
          
          # Better notebook count logic
          if [ "$NOTEBOOKS" = "null" ] || [ "$NOTEBOOKS" = "" ] || [ "$NOTEBOOKS" = "[]" ]; then
            NOTEBOOK_COUNT=0
          else
            # Try to get count, fallback to 0 if parsing fails
            NOTEBOOK_COUNT=$(echo "$NOTEBOOKS" | jq -r 'length' 2>/dev/null)
            if [ "$NOTEBOOK_COUNT" = "null" ] || [ -z "$NOTEBOOK_COUNT" ]; then
              NOTEBOOK_COUNT=0
            fi
          fi
          
          # Show what directories were affected (only if there are any)
          if [ "$AFFECTED_DIRS" != "[]" ] && [ "$AFFECTED_DIRS" != "null" ] && [ "$AFFECTED_DIRS" != "" ]; then
            echo "**📁 Affected Directories:**" >> $GITHUB_STEP_SUMMARY
            echo "$AFFECTED_DIRS" | jq -r '.[]' 2>/dev/null | while read -r dir; do
              echo "- \`$dir\`" >> $GITHUB_STEP_SUMMARY
            done || echo "- Could not parse affected directories" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Determine what actually happened based on job results rather than just notebook count
          PROCESS_RESULT="${{ needs.process-notebooks.result }}"
          
          if [ "${{ needs.setup-matrix.outputs.docs-only }}" = "true" ]; then
            echo "**📖 Documentation-Only Build**" >> $GITHUB_STEP_SUMMARY
            echo "- No notebooks executed - documentation built from existing executed notebooks" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.setup-matrix.outputs.skip-execution }}" = "true" ]; then
            echo "**⏭️ Execution Skipped**" >> $GITHUB_STEP_SUMMARY
            echo "- No notebook processing performed (skip execution flag enabled)" >> $GITHUB_STEP_SUMMARY
          elif [ "$PROCESS_RESULT" = "skipped" ] && [ "${{ inputs.execution-mode }}" = "merge" ]; then
            echo "**� Merge Mode**" >> $GITHUB_STEP_SUMMARY
            echo "- Notebook processing skipped in merge mode (using pre-executed notebooks)" >> $GITHUB_STEP_SUMMARY
          elif [ "$PROCESS_RESULT" = "success" ] || [ "$PROCESS_RESULT" = "failure" ]; then
            # We know notebooks were processed because the job ran
            echo "**🚀 Notebook Processing Results**" >> $GITHUB_STEP_SUMMARY
            
            if [ "$NOTEBOOK_COUNT" -gt 0 ]; then
              echo "- **Total Notebooks**: $NOTEBOOK_COUNT" >> $GITHUB_STEP_SUMMARY
            else
              echo "- **Notebooks Processed**: Job completed (count unavailable)" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Show what was actually done based on trigger event
            case "${{ inputs.trigger-event }}" in
              "validate")
                echo "- **Operation**: Notebook validation" >> $GITHUB_STEP_SUMMARY
                ;;
              "execute")
                echo "- **Operation**: Notebook execution" >> $GITHUB_STEP_SUMMARY
                ;;
              "security")
                echo "- **Operation**: Security scanning" >> $GITHUB_STEP_SUMMARY
                ;;
              "all")
                echo "- **Operation**: Full pipeline (validation, execution, security)" >> $GITHUB_STEP_SUMMARY
                ;;
              "html")
                echo "- **Operation**: Documentation build" >> $GITHUB_STEP_SUMMARY
                ;;
              "deprecate")
                echo "- **Operation**: Deprecation management" >> $GITHUB_STEP_SUMMARY
                ;;
              *)
                echo "- **Operation**: Notebook processing" >> $GITHUB_STEP_SUMMARY
                ;;
            esac
            
            # Show result
            if [ "$PROCESS_RESULT" = "success" ]; then
              echo "- **Status**: ✅ SUCCESS - All operations completed without errors" >> $GITHUB_STEP_SUMMARY
            else
              echo "- **Status**: ❌ FAILURE - Check job logs for error details" >> $GITHUB_STEP_SUMMARY
            fi
            
            # List specific notebooks if we can parse them
            if [ "$NOTEBOOK_COUNT" -gt 0 ] && [ "$NOTEBOOKS" != "[]" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**📄 Processed Notebooks:**" >> $GITHUB_STEP_SUMMARY
              if [ "$NOTEBOOK_COUNT" = "1" ]; then
                SINGLE_NOTEBOOK=$(echo "$NOTEBOOKS" | jq -r '.[0]' 2>/dev/null)
                if [ "$SINGLE_NOTEBOOK" != "null" ] && [ -n "$SINGLE_NOTEBOOK" ]; then
                  echo "- \`$SINGLE_NOTEBOOK\`" >> $GITHUB_STEP_SUMMARY
                fi
              else
                echo "$NOTEBOOKS" | jq -r '.[]' 2>/dev/null | while read -r notebook; do
                  if [ -n "$notebook" ] && [ "$notebook" != "null" ]; then
                    echo "- \`$notebook\`" >> $GITHUB_STEP_SUMMARY
                  fi
                done
              fi
            fi
          else
            echo "**📋 No Processing Performed**" >> $GITHUB_STEP_SUMMARY
            echo "- No notebooks matched selection criteria or processing was not required" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add error reporting section if there were failures
          if [ "${{ needs.setup-matrix.result }}" = "failure" ] || [ "${{ needs.process-notebooks.result }}" = "failure" ] || [ "${{ needs.build-documentation.result }}" = "failure" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🚨 Error Information" >> $GITHUB_STEP_SUMMARY
            echo "One or more jobs failed. Check the following:" >> $GITHUB_STEP_SUMMARY
            echo "1. **Job Logs**: Click on the failed job(s) above to see detailed error messages" >> $GITHUB_STEP_SUMMARY
            echo "2. **Common Issues**:" >> $GITHUB_STEP_SUMMARY
            echo "   - Missing dependencies in requirements.txt" >> $GITHUB_STEP_SUMMARY
            echo "   - Notebook execution errors (infinite loops, missing data, etc.)" >> $GITHUB_STEP_SUMMARY
            echo "   - Environment setup issues" >> $GITHUB_STEP_SUMMARY
            echo "   - Security vulnerabilities detected" >> $GITHUB_STEP_SUMMARY
            echo "3. **Debugging**: Use on-demand mode to test specific notebooks individually" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Add final status indicator
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Determine overall workflow status
          SETUP_RESULT="${{ needs.setup-matrix.result }}"
          PROCESS_RESULT="${{ needs.process-notebooks.result }}"
          BUILD_RESULT="${{ needs.build-documentation.result }}"
          DEPRECATION_RESULT="${{ needs.manage-deprecation.result }}"
          
          # Count successful and failed jobs
          SUCCESS_COUNT=0
          FAILURE_COUNT=0
          
          # Check each job result
          for result in "$SETUP_RESULT" "$PROCESS_RESULT" "$BUILD_RESULT" "$DEPRECATION_RESULT"; do
            case "$result" in
              "success") SUCCESS_COUNT=$((SUCCESS_COUNT + 1)) ;;
              "failure") FAILURE_COUNT=$((FAILURE_COUNT + 1)) ;;
              "skipped") ;; # Don't count skipped jobs as failures
              "cancelled") FAILURE_COUNT=$((FAILURE_COUNT + 1)) ;;
            esac
          done
          
          # Special handling for process-notebooks in merge mode
          if [ "${{ inputs.execution-mode }}" = "merge" ] && [ "$PROCESS_RESULT" = "skipped" ]; then
            echo "**Note**: Notebook processing was intentionally skipped in merge mode" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "$FAILURE_COUNT" -eq 0 ]; then
            echo "## 🎉 Workflow completed successfully!" >> $GITHUB_STEP_SUMMARY
            echo "*All required jobs completed without errors*" >> $GITHUB_STEP_SUMMARY
          elif [ "$SUCCESS_COUNT" -gt 0 ]; then
            echo "## ⚠️ Workflow completed with partial success" >> $GITHUB_STEP_SUMMARY
            echo "*Some jobs succeeded but $FAILURE_COUNT job(s) failed - see error details above*" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ❌ Workflow failed" >> $GITHUB_STEP_SUMMARY
            echo "*Multiple critical failures occurred - see error details above*" >> $GITHUB_STEP_SUMMARY
          fi
