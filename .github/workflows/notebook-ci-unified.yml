name: Unified Notebook CI/CD Pipeline

run-name: |
  ${{
    inputs.execution-mode == 'pr' && 'üîÑ PR Workflow' ||
    inputs.execution-mode == 'merge' && 'üöÄ Merge Workflow' ||
    inputs.execution-mode == 'scheduled' && '‚è∞ Scheduled Validation' ||
    inputs.execution-mode == 'on-demand' && (
      inputs.trigger-event == 'validate' && 'üîç On-Demand Validation' ||
      inputs.trigger-event == 'execute' && '‚ñ∂Ô∏è On-Demand Execution' ||
      inputs.trigger-event == 'security' && 'üõ°Ô∏è Security Scan' ||
      inputs.trigger-event == 'html' && 'üìñ Documentation Build' ||
      inputs.trigger-event == 'deprecate' && 'üè∑Ô∏è Notebook Deprecation' ||
      inputs.trigger-event == 'all' && 'üéØ Full Pipeline' ||
      'üéØ On-Demand Workflow'
    ) ||
    'Notebook CI/CD'
  }}${{ inputs.single-notebook != '' && format(' - {0}', inputs.single-notebook) || '' }}

on:
  workflow_call:
    inputs:
      # Execution Configuration
      execution-mode:
        description: 'Execution mode: pr, merge, scheduled, on-demand'
        required: true
        type: string
      trigger-event:
        description: 'Specific trigger: validate, execute, security, html, deprecate'
        required: false
        type: string
        default: 'all'
      
      # Environment Configuration
      python-version:
        description: 'Python version to use'
        required: false
        type: string
        default: '3.11'
      conda-environment:
        description: 'Custom conda environment (hstcal, stenv, etc.)'
        required: false
        type: string
      custom-requirements:
        description: 'Path to custom requirements file'
        required: false
        type: string
      
      # Notebook Selection
      single-notebook:
        description: 'Single notebook path for targeted execution'
        required: false
        type: string
      affected-directories:
        description: 'JSON array of affected directories (auto-detected or manual)'
        required: false
        type: string
        default: '[]'
      
      # Feature Flags
      enable-validation:
        description: 'Enable pytest nbval validation'
        required: false
        type: boolean
        default: true
      enable-security:
        description: 'Enable bandit security testing'
        required: false
        type: boolean
        default: true
      enable-execution:
        description: 'Enable notebook execution'
        required: false
        type: boolean
        default: true
      enable-storage:
        description: 'Enable storing outputs to gh-storage'
        required: false
        type: boolean
        default: true
      enable-html-build:
        description: 'Enable HTML documentation build'
        required: false
        type: boolean
        default: false
      
      # Post-processing
      post-processing-script:
        description: 'Optional post-processing script path'
        required: false
        type: string
      
      # Deprecation
      deprecation-days:
        description: 'Days until deprecation (default: 60)'
        required: false
        type: number
        default: 60
      
      # Custom Runner Configuration
      custom-runner-config:
        description: 'Enable custom runner selection based on ci_config.txt'
        required: false
        type: boolean
        default: false

    secrets:
      CASJOBS_USERID:
        required: false
      CASJOBS_PW:
        required: false

jobs:
  # Change Detection and Matrix Setup
  setup-matrix:
    runs-on: ubuntu-24.04
    outputs:
      matrix-notebooks: ${{ steps.setup.outputs.matrix-notebooks }}
      runner-config: ${{ steps.setup.outputs.runner-config }}
      affected-dirs: ${{ steps.setup.outputs.affected-dirs }}
      skip-execution: ${{ steps.setup.outputs.skip-execution }}
      docs-only: ${{ steps.setup.outputs.docs-only }}
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
          
      - name: Setup matrix and detect changes
        id: setup
        run: |
          # Initialize variables
          SKIP_EXECUTION=false
          DOCS_ONLY=false
          MATRIX_NOTEBOOKS="[]"
          AFFECTED_DIRS="${{ inputs.affected-directories }}"
          
          case "${{ inputs.execution-mode }}" in
            "pr")
              echo "üîÑ PR Mode: Detecting changed files"
              if [ "$GITHUB_EVENT_NAME" = "pull_request" ]; then
                BASE_REF=$(jq -r .pull_request.base.ref < "$GITHUB_EVENT_PATH")
                git fetch origin "$BASE_REF"
                CHANGED_FILES=$(git diff --name-only origin/$BASE_REF...HEAD)
              else
                CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
              fi
              
              # Detect docs-only changes
              DOCS_ONLY=true
              NOTEBOOKS_CHANGED=false
              declare -a CHANGED_NOTEBOOKS
              declare -a AFFECTED_DIRECTORIES
              
              while IFS= read -r file; do
                [[ -z "$file" ]] && continue
                case "$file" in
                  notebooks/*.ipynb)
                    NOTEBOOKS_CHANGED=true
                    DOCS_ONLY=false
                    CHANGED_NOTEBOOKS+=("$file")
                    dir=$(dirname "$file")
                    if [[ ! " ${AFFECTED_DIRECTORIES[*]} " =~ " $dir " ]]; then
                      AFFECTED_DIRECTORIES+=("$dir")
                    fi
                    ;;
                  notebooks/*/requirements.txt|requirements.txt|pyproject.toml)
                    echo "üì¶ Requirements file changed: $file"
                    NOTEBOOKS_CHANGED=true
                    DOCS_ONLY=false
                    dir=$(dirname "$file")
                    if [[ "$file" == "requirements.txt" || "$file" == "pyproject.toml" ]]; then
                      # Root requirements file affects all notebooks
                      echo "üåê Root requirements file changed - affecting all notebooks"
                      AFFECTED_DIRECTORIES=("notebooks")
                    else
                      # Directory-specific requirements file
                      echo "üìÅ Directory requirements file changed: $dir"
                      if [[ ! " ${AFFECTED_DIRECTORIES[*]} " =~ " $dir " ]]; then
                        AFFECTED_DIRECTORIES+=("$dir")
                      fi
                    fi
                    ;;
                  *.md|*.html|*.css|*.js|_config.yml|_toc.yml)
                    # Keep DOCS_ONLY=true, but enable HTML build
                    ;;
                  *)
                    DOCS_ONLY=false
                    ;;
                esac
              done <<< "$CHANGED_FILES"
              
              # After processing all changed files, find notebooks in affected directories
              if [ ${#AFFECTED_DIRECTORIES[@]} -gt 0 ]; then
                echo "üìÅ Finding notebooks in affected directories: ${AFFECTED_DIRECTORIES[*]}"
                declare -a ALL_AFFECTED_NOTEBOOKS
                
                for dir in "${AFFECTED_DIRECTORIES[@]}"; do
                  echo "üîç Searching for notebooks in: $dir"
                  while IFS= read -r notebook; do
                    [[ -z "$notebook" ]] && continue
                    echo "üìì Found notebook: $notebook"
                    ALL_AFFECTED_NOTEBOOKS+=("$notebook")
                  done < <(find "$dir" -name '*.ipynb' -type f 2>/dev/null)
                done
                
                # Combine explicitly changed notebooks with those in affected directories
                # Remove duplicates by using associative array
                declare -A UNIQUE_NOTEBOOKS
                for notebook in "${CHANGED_NOTEBOOKS[@]}" "${ALL_AFFECTED_NOTEBOOKS[@]}"; do
                  [[ -n "$notebook" ]] && UNIQUE_NOTEBOOKS["$notebook"]=1
                done
                
                # Convert back to regular array
                CHANGED_NOTEBOOKS=()
                for notebook in "${!UNIQUE_NOTEBOOKS[@]}"; do
                  CHANGED_NOTEBOOKS+=("$notebook")
                done
                
                echo "üìã Total unique notebooks to process: ${#CHANGED_NOTEBOOKS[@]}"
                for notebook in "${CHANGED_NOTEBOOKS[@]}"; do
                  echo "  - $notebook"
                done
              fi
              
              if [ "$DOCS_ONLY" = "true" ]; then
                echo "üìö Docs-only changes detected"
                SKIP_EXECUTION=true
              elif [ ${#CHANGED_NOTEBOOKS[@]} -gt 0 ]; then
                MATRIX_NOTEBOOKS=$(printf '%s\n' "${CHANGED_NOTEBOOKS[@]}" | jq -R . | jq -s -c .)
                AFFECTED_DIRS=$(printf '%s\n' "${AFFECTED_DIRECTORIES[@]}" | jq -R . | jq -s -c .)
                echo "‚úÖ Matrix populated with ${#CHANGED_NOTEBOOKS[@]} notebooks"
              else
                echo "‚ö†Ô∏è No notebooks found to process"
                MATRIX_NOTEBOOKS="[]"
                AFFECTED_DIRS="[]"
              fi
              ;;
              
            "merge")
              echo "üöÄ Merge Mode: Full repository processing"  
              MATRIX_NOTEBOOKS=$(find notebooks/ -name '*.ipynb' | jq -R -s -c 'split("\n")[:-1] | map(select(. != ""))')
              AFFECTED_DIRS='["notebooks"]'
              ;;
              
            "scheduled")
              echo "‚è∞ Scheduled Mode: All notebooks validation"
              MATRIX_NOTEBOOKS=$(find notebooks/ -name '*.ipynb' | jq -R -s -c 'split("\n")[:-1] | map(select(. != ""))')
              AFFECTED_DIRS='["notebooks"]'
              ;;
              
            "on-demand")
              echo "üéØ On-demand Mode"
              # Check if this is a documentation-only build
              if [ "${{ inputs.trigger-event }}" = "html" ]; then
                echo "üìö Documentation-only build: skipping notebook processing"
                SKIP_EXECUTION=true
                MATRIX_NOTEBOOKS='[]'
                AFFECTED_DIRS='[]'
              elif [ -n "${{ inputs.single-notebook }}" ]; then
                echo "üìÑ Single notebook specified: ${{ inputs.single-notebook }}"
                
                # Check if it's a full path or just a filename
                if [[ "${{ inputs.single-notebook }}" == *"/"* ]]; then
                  # Full path provided
                  NOTEBOOK_PATH="${{ inputs.single-notebook }}"
                  echo "üìÅ Full path provided: $NOTEBOOK_PATH"
                else
                  # Just filename provided - find the full path
                  echo "üîç Filename only provided, searching for: ${{ inputs.single-notebook }}"
                  NOTEBOOK_PATH=$(find notebooks/ -name "${{ inputs.single-notebook }}" -type f | head -1)
                  if [ -z "$NOTEBOOK_PATH" ]; then
                    echo "‚ùå Notebook not found: ${{ inputs.single-notebook }}"
                    echo "Available notebooks:"
                    find notebooks/ -name '*.ipynb' | head -10
                    exit 1
                  fi
                  echo "‚úÖ Found notebook at: $NOTEBOOK_PATH"
                fi
                
                MATRIX_NOTEBOOKS=$(echo "$NOTEBOOK_PATH" | jq -R -s -c 'split("\n")[:-1]')
                # Calculate the directory for the single notebook
                SINGLE_NOTEBOOK_DIR=$(dirname "$NOTEBOOK_PATH")
                AFFECTED_DIRS=$(echo "$SINGLE_NOTEBOOK_DIR" | jq -R -s -c 'split("\n")[:-1]')
                echo "üìÅ Calculated directory: $SINGLE_NOTEBOOK_DIR"
              else
                MATRIX_NOTEBOOKS=$(find notebooks/ -name '*.ipynb' | jq -R -s -c 'split("\n")[:-1] | map(select(. != ""))')
                AFFECTED_DIRS='["notebooks"]'
              fi
              ;;
          esac
          
          # Filter out deprecated notebooks during merge workflows
          if [ "${{ inputs.execution-mode }}" = "merge" ] && [ "$MATRIX_NOTEBOOKS" != "[]" ]; then
            echo "üîç Checking for deprecated notebooks to skip execution..."
            
            # Create a temporary file with the current notebook list
            echo "$MATRIX_NOTEBOOKS" | jq -r '.[]' > /tmp/notebooks_to_check.txt
            
            # Filter out deprecated notebooks
            FILTERED_NOTEBOOKS=""
            while IFS= read -r notebook; do
              if [ -f "$notebook" ]; then
                # Check if notebook has deprecation metadata - use output instead of exit code
                # Create a temporary Python script to check deprecation
                cat > /tmp/check_deprecation.py << 'EOF'
          import json, sys, os
          notebook_path = os.environ["NOTEBOOK_PATH"]
          try:
              with open(notebook_path, "r", encoding="utf-8") as f:
                  nb = json.load(f)
              
              # Check for deprecation in multiple ways
              is_deprecated = False
              
              # Method 1: Check notebook metadata
              if "metadata" in nb and "deprecated" in nb.get("metadata", {}):
                  is_deprecated = True
              
              # Method 2: Check for cells with deprecated tags
              if not is_deprecated:
                  for cell in nb.get("cells", []):
                      if cell.get("cell_type") == "markdown" and "tags" in cell.get("metadata", {}):
                          if "deprecated" in cell["metadata"]["tags"]:
                              is_deprecated = True
                              break
              
              # Method 3: Text-based search for backward compatibility
              if not is_deprecated:
                  for cell in nb.get("cells", []):
                      source = "".join(cell.get("source", []))
                      if "DEPRECATED" in source or "deprecated" in source:
                          is_deprecated = True
                          break
              
              # Output result - do not use exit codes
              if is_deprecated:
                  print("DEPRECATED")
              else:
                  print("ACTIVE")
                  
          except Exception as e:
              print("ERROR")
          EOF
                
                DEPRECATION_CHECK=$(NOTEBOOK_PATH="$notebook" python3 /tmp/check_deprecation.py 2>/dev/null)
                rm -f /tmp/check_deprecation.py
                
                # Add to filtered list if not deprecated
                if [ "$DEPRECATION_CHECK" = "ACTIVE" ]; then
                  if [ -z "$FILTERED_NOTEBOOKS" ]; then
                    FILTERED_NOTEBOOKS="\"$notebook\""
                  else
                    FILTERED_NOTEBOOKS="$FILTERED_NOTEBOOKS,\"$notebook\""
                  fi
                elif [ "$DEPRECATION_CHECK" = "DEPRECATED" ]; then
                  echo "‚ö†Ô∏è Skipping deprecated notebook: $notebook"
                else
                  echo "‚ö†Ô∏è Error checking deprecation status for $notebook - including in execution"
                  if [ -z "$FILTERED_NOTEBOOKS" ]; then
                    FILTERED_NOTEBOOKS="\"$notebook\""
                  else
                    FILTERED_NOTEBOOKS="$FILTERED_NOTEBOOKS,\"$notebook\""
                  fi
                fi
              fi
            done < /tmp/notebooks_to_check.txt
            
            # Clean up temp files
            rm -f /tmp/notebooks_to_check.txt
            
            # Update the matrix with filtered notebooks
            if [ -n "$FILTERED_NOTEBOOKS" ]; then
              MATRIX_NOTEBOOKS="[$FILTERED_NOTEBOOKS]"
              echo "‚úÖ Filtered notebook matrix (deprecated notebooks skipped): $MATRIX_NOTEBOOKS"
            else
              MATRIX_NOTEBOOKS="[]"
              echo "‚ÑπÔ∏è All notebooks are deprecated - no execution needed"
            fi
          fi
          
          # Custom Runner Configuration
          if [ "${{ inputs.custom-runner-config }}" = "true" ] && [ "$MATRIX_NOTEBOOKS" != "[]" ]; then
            echo "üñ•Ô∏è Custom runner configuration enabled"
            
            # Create runner config JSON mapping notebooks to runners
            RUNNER_CONFIG='{'
            FIRST_ENTRY=true
            
            # Create a temporary file to store notebooks to avoid subshell issues
            echo "$MATRIX_NOTEBOOKS" | jq -r '.[]' > /tmp/matrix_notebooks.txt 2>/dev/null
            
            while IFS= read -r notebook; do
              if [ -n "$notebook" ]; then
                # Look up runner for this notebook in ci_config.txt
                if [ -f "ci_config.txt" ]; then
                  CUSTOM_RUNNER=$(grep "^${notebook}:" ci_config.txt 2>/dev/null | cut -d':' -f2 | tr -d '[:space:]' || echo "")
                else
                  CUSTOM_RUNNER=""
                fi
                
                if [ -n "$CUSTOM_RUNNER" ]; then
                  echo "üéØ Found custom runner for $notebook: '$CUSTOM_RUNNER'"
                  # For GitHub-hosted larger runners (runner groups), use group format
                  if [[ "$CUSTOM_RUNNER" == jwst-pipeline-notebooks-* ]]; then
                    RUNNER_VALUE="{\"group\":\"${CUSTOM_RUNNER}\"}"
                  else
                    # For regular runners, use simple string format
                    RUNNER_VALUE="\"${CUSTOM_RUNNER}\""
                  fi
                else
                  echo "üîß No custom runner for $notebook, using default: ubuntu-latest"
                  # ubuntu-latest uses simple string format
                  RUNNER_VALUE="\"ubuntu-latest\""
                fi
                
                # Build JSON entry for runner config
                if [ "$FIRST_ENTRY" = "true" ]; then
                  RUNNER_CONFIG="${RUNNER_CONFIG}\"${notebook}\":${RUNNER_VALUE}"
                  FIRST_ENTRY=false
                else
                  RUNNER_CONFIG="${RUNNER_CONFIG},\"${notebook}\":${RUNNER_VALUE}"
                fi
              fi
            done < /tmp/matrix_notebooks.txt
            
            # Clean up temporary file
            rm -f /tmp/matrix_notebooks.txt
            
            # Add default runner and close JSON
            RUNNER_CONFIG="${RUNNER_CONFIG},\"default\":\"ubuntu-latest\"}"
            echo "‚úÖ Runner config: $RUNNER_CONFIG"
            
            if [ ! -f "ci_config.txt" ]; then
              echo "‚ö†Ô∏è Custom runner config enabled but ci_config.txt not found - using default runners"
            fi
          elif [ "${{ inputs.custom-runner-config }}" = "true" ] && [ "$MATRIX_NOTEBOOKS" = "[]" ]; then
            echo "‚ÑπÔ∏è Custom runner config enabled but no notebooks to process"
            RUNNER_CONFIG='{"default":"ubuntu-latest"}'
          else
            # No custom runners - use default for all
            RUNNER_CONFIG='{"default":"ubuntu-latest"}'
          fi
          
          echo "matrix-notebooks=$MATRIX_NOTEBOOKS" >> $GITHUB_OUTPUT
          echo "runner-config=$RUNNER_CONFIG" >> $GITHUB_OUTPUT
          echo "affected-dirs=$AFFECTED_DIRS" >> $GITHUB_OUTPUT  
          echo "skip-execution=$SKIP_EXECUTION" >> $GITHUB_OUTPUT
          echo "docs-only=$DOCS_ONLY" >> $GITHUB_OUTPUT
          
          echo "üìä Matrix Setup Complete:"
          echo "  Notebooks: $MATRIX_NOTEBOOKS"
          echo "  Runner Config: $RUNNER_CONFIG"
          echo "  Affected Dirs: $AFFECTED_DIRS"
          echo "  Skip Execution: $SKIP_EXECUTION"
          echo "  Docs Only: $DOCS_ONLY"
          
          # Debug: Test JSON validity
          echo "üß™ Testing JSON validity:"
          echo "$RUNNER_CONFIG" | jq '.' >/dev/null 2>&1 && echo "‚úÖ Runner config JSON is valid" || echo "‚ùå Runner config JSON is invalid"
          
          # Debug: Show JSON keys
          echo "üîë Runner config keys:"
          echo "$RUNNER_CONFIG" | jq -r 'keys[]' 2>/dev/null || echo "‚ùå Failed to extract keys"

  # Main Notebook Processing
  process-notebooks:
    needs: setup-matrix
    # environment: ci_env  # Temporarily removed to test runner assignment
    if: |
      needs.setup-matrix.outputs.skip-execution != 'true' && 
      needs.setup-matrix.outputs.matrix-notebooks != '[]' &&
      inputs.execution-mode != 'merge' &&
      inputs.trigger-event != 'deprecate'
    runs-on: ${{ fromJson(needs.setup-matrix.outputs.runner-config)[matrix.notebook] || 'ubuntu-latest' }}
    outputs:
      execution-results: ${{ steps.collect-results.outputs.results }}
      total-notebooks: ${{ steps.collect-results.outputs.total }}
      successful-notebooks: ${{ steps.collect-results.outputs.successful }}
      failed-notebooks: ${{ steps.collect-results.outputs.failed }}
    strategy:
      fail-fast: false
      matrix:
        notebook: ${{ fromJson(needs.setup-matrix.outputs.matrix-notebooks) }}
    env:
      CASJOBS_USERID: ${{ secrets.CASJOBS_USERID }}
      CASJOBS_PW: ${{ secrets.CASJOBS_PW }}
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
          
      - name: Debug Runner Information
        run: |
          echo "üñ•Ô∏è Runner Debug Information:"
          echo "  Matrix Notebook: '${{ matrix.notebook }}'"
          echo "  Runner Config JSON: '${{ needs.setup-matrix.outputs.runner-config }}'"
          echo "  JSON Lookup Result: '${{ fromJson(needs.setup-matrix.outputs.runner-config)[matrix.notebook] }}'"
          echo "  Runner Assignment: '${{ fromJson(needs.setup-matrix.outputs.runner-config)[matrix.notebook] || 'ubuntu-latest' }}'"
          echo "  Format: Either string for regular runners or {group: name} object for GitHub-hosted larger runners"
          echo "  Runner Name: ${{ runner.name }}"
          echo "  Runner OS: ${{ runner.os }}"
          echo "  Runner Arch: ${{ runner.arch }}"
          echo "  GitHub Actor: ${{ github.actor }}"
          echo "  Repository: ${{ github.repository }}"
          echo "  Workflow: ${{ github.workflow }}"
          echo "  Job: ${{ github.job }}"
          echo "  Run ID: ${{ github.run_id }}"
          echo ""
          echo "üîç System Information:"
          echo "  Hostname: $(hostname || echo 'N/A')"
          echo "  Available CPU cores: $(nproc || echo 'N/A')"
          echo "  Available memory: $(free -h 2>/dev/null | grep '^Mem:' | awk '{print $2}' || echo 'N/A')"
          echo "  Disk space: $(df -h . 2>/dev/null | tail -1 | awk '{print $4}' || echo 'N/A')"
          echo ""
          echo "üìù JSON Lookup Test:"
          echo '${{ needs.setup-matrix.outputs.runner-config }}' | jq '.' || echo "‚ùå Invalid JSON"
          echo "üîë Available keys in runner config:"
          echo '${{ needs.setup-matrix.outputs.runner-config }}' | jq -r 'keys[]' || echo "‚ùå Failed to extract keys"
          echo "üéØ Direct key test:"
          echo '${{ needs.setup-matrix.outputs.runner-config }}' | jq -r '.["${{ matrix.notebook }}"]' || echo "‚ùå Key lookup failed"
          
      - name: Check if notebook is deprecated
        id: deprecation-check
        run: |
          notebook="${{ matrix.notebook }}"
          
          # Check for deprecation markers in notebook
          if grep -q "DEPRECATED\|deprecated\|DEPRECATION" "$notebook"; then
            echo "‚ö†Ô∏è Notebook marked as deprecated: $notebook"
            echo "deprecated=true" >> $GITHUB_OUTPUT
          else
            echo "deprecated=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up Python environment with micromamba
        uses: mamba-org/setup-micromamba@v2.0.4
        with:
          environment-name: ci-env
          init-shell: bash
          create-args: "python=${{ inputs.python-version }} pip jupyter nbval nbconvert bandit pytest"
          cache-environment: false

      - name: Set up custom conda environment
        if: inputs.conda-environment != ''
        run: |
          echo "üîß Setting up custom conda environment: ${{ inputs.conda-environment }}"
          # Create environment with specified conda environment packages
          micromamba install -n ci-env ${{ inputs.conda-environment }} -y

      - name: Install requirements
        run: |
          notebook="${{ matrix.notebook }}"
          nb_dir=$(dirname "$notebook")
          
          # Activate the micromamba environment
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          
          # Install custom requirements if specified
          if [ -n "${{ inputs.custom-requirements }}" ]; then
            echo "Installing custom requirements: ${{ inputs.custom-requirements }}"
            pip install -r "${{ inputs.custom-requirements }}"
          elif [ -f "$nb_dir/requirements.txt" ]; then
            echo "Installing directory-specific requirements: $nb_dir/requirements.txt"
            pip install -r "$nb_dir/requirements.txt"
          else
            echo "No requirements.txt found in $nb_dir - using base environment only"
          fi

      - name: Validate notebook
        if: inputs.enable-validation == true && (inputs.trigger-event == 'all' || inputs.trigger-event == 'validate')
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          echo "üîç Validating notebook: ${{ matrix.notebook }}"
          # Clear outputs to ensure clean validation
          jupyter nbconvert --clear-output --inplace "${{ matrix.notebook }}"
          pytest --nbval --nbval-cell-timeout=4000 "${{ matrix.notebook }}"

      - name: Security scan
        if: inputs.enable-security == true && (inputs.trigger-event == 'all' || inputs.trigger-event == 'security')
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          echo "üõ°Ô∏è Security scanning: ${{ matrix.notebook }}"
          notebook="${{ matrix.notebook }}"
          jupyter nbconvert --to script "$notebook"
          py_file="${notebook%.ipynb}.py"
          if [ -f "$py_file" ]; then
            bandit "$py_file" || echo "Security warnings found"
            rm -f "$py_file"
          fi

      - name: Execute notebook
        if: inputs.enable-execution == true && (inputs.trigger-event == 'all' || inputs.trigger-event == 'execute')
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate ci-env
          echo "‚ñ∂Ô∏è Executing notebook: ${{ matrix.notebook }}"
          jupyter nbconvert --to notebook --execute --inplace "${{ matrix.notebook }}"

      - name: Store executed notebook to gh-storage
        if: |
          inputs.enable-storage == true && 
          steps.deprecation-check.outputs.deprecated != 'true' &&
          success() && 
          (inputs.execution-mode == 'pr' || inputs.execution-mode == 'merge' || inputs.execution-mode == 'on-demand' || inputs.trigger-event == 'execute')
        run: |
          echo "üíæ Storing executed notebook to gh-storage"
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          
          notebook="${{ matrix.notebook }}"
          
          if [ "${{ inputs.execution-mode }}" = "pr" ]; then
            echo "üîÑ PR mode: Force-pushing ONLY the executed notebook to gh-storage"
            
            # Store current state
            current_branch=$(git branch --show-current)
            echo "üìç Current branch: $current_branch"
            
            # Create a backup copy of the executed notebook BEFORE any branch operations
            temp_notebook="/tmp/executed_$(basename "$notebook")"
            cp "$notebook" "$temp_notebook"
            echo "üìã Backed up executed notebook to: $temp_notebook"
            
            # Stash the executed notebook changes to allow clean branch switch
            git add "$notebook"
            git stash push -m "Temporary stash of executed notebook for gh-storage" -- "$notebook"
            echo "ÔøΩ Stashed executed notebook changes for clean branch switch"
            
            # Switch to gh-storage branch (create if doesn't exist)
            if git ls-remote --exit-code origin gh-storage >/dev/null 2>&1; then
              echo "üì¶ Using existing gh-storage branch"
              git fetch origin gh-storage
              git checkout gh-storage
            else
              echo "üÜï Creating new gh-storage branch"
              git checkout --orphan gh-storage
              git rm -rf . >/dev/null 2>&1 || true
            fi
            
            # Create directory structure and copy ONLY the executed notebook from backup
            echo "ÔøΩ Setting up directory: $(dirname "$notebook")"
            mkdir -p "$(dirname "$notebook")"
            cp "$temp_notebook" "$notebook"
            echo "üìã Copied executed notebook from backup: $notebook"
            
            # Stage ONLY this notebook file
            git add "$notebook"
            
            # Check if there are actual changes to commit
            if git diff --cached --quiet; then
              echo "‚ÑπÔ∏è No changes detected in $notebook"
            else
              echo "‚úÖ Changes detected, committing notebook"
              git commit -m "Update executed notebook $notebook from PR #${{ github.event.number }} [skip ci]"
              
              # Try regular push first, then pull-rebase-push if conflicts
              if git push origin gh-storage; then
                echo "üöÄ Successfully pushed $notebook to gh-storage"
              else
                echo "‚ö†Ô∏è Push failed due to conflicts, attempting rebase..."
                git pull --rebase origin gh-storage
                git push origin gh-storage
                echo "üöÄ Successfully pushed $notebook to gh-storage after rebase"
              fi
            fi
            
            # Clean up backup file and return to original branch
            rm -f "$temp_notebook"
            
            # Return to original branch (handle empty branch name)
            if [ -n "$current_branch" ]; then
              git checkout "$current_branch"
              echo "üîÑ Returned to original branch: $current_branch"
            else
              # Fallback to default branch if current_branch is empty
              git checkout "${{ github.ref_name }}" || git checkout main || git checkout master
              echo "üîÑ Returned to default branch (current_branch was empty)"
            fi
            
            # Clean up stash if it exists
            if git stash list | grep -q "Temporary stash of executed notebook for gh-storage"; then
              git stash drop
              echo "üßπ Cleaned up temporary stash"
            fi
            
          else
            echo "üîÑ Merge/Execute mode: Adding notebook to gh-storage"
            
            # Store current state
            current_branch=$(git branch --show-current)
            echo "üìç Current branch: $current_branch"
            
            # Create a backup copy of the executed notebook BEFORE any branch operations
            temp_notebook="/tmp/executed_$(basename "$notebook")"
            cp "$notebook" "$temp_notebook"
            echo "üìã Backed up executed notebook to: $temp_notebook"
            
            # Stash the executed notebook changes to allow clean branch switch
            git add "$notebook"
            git stash push -m "Temporary stash of executed notebook for gh-storage" -- "$notebook"
            echo "ÔøΩ Stashed executed notebook changes for clean branch switch"
            
            # Switch to gh-storage branch
            if git ls-remote --exit-code origin gh-storage >/dev/null 2>&1; then
              echo "üì¶ Using existing gh-storage branch"
              git fetch origin gh-storage
              git checkout gh-storage
            else
              echo "üÜï Creating new gh-storage branch"
              git checkout --orphan gh-storage
              git rm -rf . >/dev/null 2>&1 || true
            fi
            
            # Create directory structure and copy the executed notebook from backup
            echo "ÔøΩ Setting up directory: $(dirname "$notebook")"  
            mkdir -p "$(dirname "$notebook")"
            cp "$temp_notebook" "$notebook"
            echo "üìã Copied executed notebook from backup: $notebook"
            
            # Stage and commit the notebook
            git add "$notebook"
            if git diff --cached --quiet; then
              echo "‚ÑπÔ∏è No changes detected in $notebook"
            else
              echo "‚úÖ Changes detected, committing notebook"
              git commit -m "Update executed notebook $notebook [skip ci]"
              
              # Try regular push first, then pull-rebase-push if conflicts
              if git push origin gh-storage; then
                echo "üöÄ Successfully pushed $notebook to gh-storage"
              else
                echo "‚ö†Ô∏è Push failed due to conflicts, attempting rebase..."
                git pull --rebase origin gh-storage
                git push origin gh-storage
                echo "üöÄ Successfully pushed $notebook to gh-storage after rebase"
              fi
            fi
            
            # Clean up backup file and return to original branch
            rm -f "$temp_notebook"
            
            # Return to original branch (handle empty branch name)
            if [ -n "$current_branch" ]; then
              git checkout "$current_branch"
              echo "üîÑ Returned to original branch: $current_branch"
            else
              # Fallback to default branch if current_branch is empty
              git checkout "${{ github.ref_name }}" || git checkout main || git checkout master
              echo "üîÑ Returned to default branch (current_branch was empty)"
            fi
            
            # Clean up stash if it exists
            if git stash list | grep -q "Temporary stash of executed notebook for gh-storage"; then
              git stash drop
              echo "üßπ Cleaned up temporary stash"
            fi
          fi

      - name: Record execution result
        if: always()
        run: |
          # Record the result for this notebook
          notebook="${{ matrix.notebook }}"
          result="${{ job.status }}"
          
          echo "üìä Recording result for $notebook: $result"
          
          # Create a results directory if it doesn't exist
          mkdir -p /tmp/notebook-results
          
          # Write result to a file
          echo "$notebook:$result" >> /tmp/notebook-results/execution-results.txt
          
          # Also create individual result files for easier parsing
          if [ "$result" = "success" ]; then
            echo "$notebook" >> /tmp/notebook-results/successful.txt
          else
            echo "$notebook" >> /tmp/notebook-results/failed.txt
          fi

      - name: Collect execution results
        id: collect-results
        if: always()
        run: |
          # This will run after all matrix jobs complete
          # We'll collect results from the artifact system in the summary job instead
          echo "results=pending" >> $GITHUB_OUTPUT
          echo "total=1" >> $GITHUB_OUTPUT
          echo "successful=0" >> $GITHUB_OUTPUT  
          echo "failed=0" >> $GITHUB_OUTPUT

  # HTML Documentation Build
  build-documentation:
    needs: [setup-matrix, process-notebooks]
    if: |
      always() && 
      inputs.enable-html-build == true &&
      (needs.setup-matrix.outputs.docs-only == 'true' || 
       inputs.execution-mode == 'merge' ||
       inputs.trigger-event == 'html' ||
       (inputs.execution-mode == 'on-demand' && (needs.process-notebooks.result == 'success' || needs.process-notebooks.result == 'failure')) ||
       (needs.process-notebooks.result == 'success' && inputs.execution-mode != 'merge'))
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v5
        with:
          ref: ${{ (inputs.execution-mode == 'merge' || inputs.trigger-event == 'html') && 'gh-storage' || github.ref }}
          fetch-depth: 0
          
      - name: Fetch executed notebooks from gh-storage
        if: inputs.execution-mode == 'merge' || inputs.trigger-event == 'html'
        run: |
          echo "üì¶ Fetching executed notebooks from gh-storage branch"
          git fetch origin gh-storage
          git checkout gh-storage
          echo "‚úÖ Switched to gh-storage branch with executed notebooks"
          
          # Merge static content from main branch to include updated docs/HTML files
          echo "üîÑ Merging static documentation files from main branch"
          
          # Fetch the main branch first
          git fetch origin main
          
          # Checkout specific files from main branch, ignore errors if files don't exist
          git checkout origin/main -- docs/ 2>/dev/null || echo "‚ÑπÔ∏è No docs/ directory in main"
          git checkout origin/main -- *.md 2>/dev/null || echo "‚ÑπÔ∏è No markdown files in main root"
          git checkout origin/main -- _config.yml 2>/dev/null || echo "‚ÑπÔ∏è No _config.yml in main"
          git checkout origin/main -- _toc.yml 2>/dev/null || echo "‚ÑπÔ∏è No _toc.yml in main"
          git checkout origin/main -- *.html 2>/dev/null || echo "‚ÑπÔ∏è No HTML files in main root"
          git checkout origin/main -- *.css 2>/dev/null || echo "‚ÑπÔ∏è No CSS files in main root"
          git checkout origin/main -- *.js 2>/dev/null || echo "‚ÑπÔ∏è No JS files in main root"
          
          echo "‚úÖ Static documentation files merged from main branch"
          echo "üìã Current working directory contents:"
          find . -name "*.html" -o -name "*.md" -o -name "_*.yml" -o -name "*.ipynb" | head -10
          
      - name: Add failure warnings to notebooks
        if: inputs.execution-mode == 'on-demand' && needs.process-notebooks.result == 'failure'
        run: |
          echo "‚ö†Ô∏è Adding failure warnings to notebooks that may have failed execution"
          
          # Get the list of notebooks that were processed
          NOTEBOOKS='${{ needs.setup-matrix.outputs.matrix-notebooks }}'
          
          if [ "$NOTEBOOKS" != "[]" ] && [ "$NOTEBOOKS" != "null" ] && [ "$NOTEBOOKS" != "" ]; then
            echo "$NOTEBOOKS" | jq -r '.[]' 2>/dev/null | while read -r notebook; do
              if [ -f "$notebook" ]; then
                echo "üîß Adding warning banner to: $notebook"
                
                # Create a temporary Python script to add the warning banner
                cat > add_warning.py << 'EOF'
          import json
          import sys
          
          notebook_path = sys.argv[1]
          
          try:
              with open(notebook_path, 'r', encoding='utf-8') as f:
                  nb = json.load(f)
              
              # Create warning banner cell
              warning_cell = {
                  "cell_type": "markdown",
                  "metadata": {
                      "tags": ["execution-warning"]
                  },
                  "source": [
                      "<div style='background-color: #fff3cd; border: 1px solid #ffeaa7; border-radius: 4px; padding: 15px; margin: 10px 0; border-left: 4px solid #f39c12;'>\n",
                      "<h3 style='color: #856404; margin-top: 0;'>‚ö†Ô∏è EXECUTION WARNING</h3>\n",
                      "<p style='color: #856404; margin-bottom: 0;'><strong>This notebook may not execute properly in the current environment.</strong></p>\n",
                      "<p style='color: #856404; margin-bottom: 0;'>Some cells may have failed during automated testing. Please review the notebook content and test manually before use.</p>\n",
                      "<p style='color: #856404; margin-bottom: 0; font-size: 0.9em;'><em>Generated during CI/CD pipeline - some outputs may be incomplete or missing.</em></p>\n",
                      "</div>\n"
                  ]
              }
              
              # Check if warning already exists
              has_warning = False
              for cell in nb.get('cells', []):
                  if cell.get('cell_type') == 'markdown' and 'tags' in cell.get('metadata', {}):
                      if 'execution-warning' in cell['metadata']['tags']:
                          has_warning = True
                          break
              
              # Add warning at the beginning if not already present
              if not has_warning:
                  nb['cells'].insert(0, warning_cell)
                  
                  with open(notebook_path, 'w', encoding='utf-8') as f:
                      json.dump(nb, f, indent=2, ensure_ascii=False)
                  
                  print(f"‚úÖ Added execution warning to {notebook_path}")
              else:
                  print(f"‚ÑπÔ∏è Warning already exists in {notebook_path}")
                  
          except Exception as e:
              print(f"‚ùå Error processing {notebook_path}: {e}")
          EOF
                
                # Run the Python script to add warning
                python add_warning.py "$notebook"
                rm -f add_warning.py
              else
                echo "‚ö†Ô∏è Notebook not found: $notebook"
              fi
            done
          else
            echo "‚ÑπÔ∏è No notebooks to process for warnings"
          fi

      - name: Add deprecation warnings to notebooks
        run: |
          echo "üè∑Ô∏è Checking for deprecated notebooks and adding deprecation warnings"
          
          # Find all notebooks in the current directory
          find . -name "*.ipynb" -type f | while read -r notebook; do
            if [ -f "$notebook" ]; then
              echo "üîç Checking for deprecation in: $notebook"
              
              # Create a temporary Python script to check and add deprecation warnings
              cat > add_deprecation_warning.py << 'EOF'
          import json
          import sys
          from datetime import datetime
          import re
          
          notebook_path = sys.argv[1]
          
          try:
              with open(notebook_path, 'r', encoding='utf-8') as f:
                  nb = json.load(f)
              
              # Check if notebook has deprecation metadata or content
              is_deprecated = False
              deprecation_date = None
              has_existing_warning = False
              
              # Method 1: Check for cells with deprecated tag OR existing deprecation-warning tag
              for cell in nb.get('cells', []):
                  if cell.get('cell_type') == 'markdown' and 'tags' in cell.get('metadata', {}):
                      tags = cell['metadata']['tags']
                      if 'deprecated' in tags:
                          is_deprecated = True
                          # Try to extract date from existing deprecation content
                          source = ''.join(cell.get('source', []))
                          date_match = re.search(r'(\d{4}-\d{2}-\d{2})', source)
                          if date_match:
                              deprecation_date = date_match.group(1)
                      elif 'deprecation-warning' in tags:
                          # Already has a deprecation warning, don't add another
                          has_existing_warning = True
                          print(f"‚ÑπÔ∏è Deprecation warning already exists in {notebook_path}")
                          break
                  if is_deprecated or has_existing_warning:
                      break
              
              # Method 2: Check notebook metadata for deprecation info
              if not is_deprecated and 'metadata' in nb:
                  nb_metadata = nb['metadata']
                  if 'deprecated' in nb_metadata:
                      is_deprecated = True
                      if isinstance(nb_metadata['deprecated'], dict):
                          deprecation_date = nb_metadata['deprecated'].get('date')
                      elif isinstance(nb_metadata['deprecated'], str):
                          # Try to parse as date
                          if re.match(r'\d{4}-\d{2}-\d{2}', nb_metadata['deprecated']):
                              deprecation_date = nb_metadata['deprecated']
              
              # Method 3: Text-based search (backward compatibility)
              if not is_deprecated:
                  for cell in nb.get('cells', []):
                      source = ''.join(cell.get('source', []))
                      if re.search(r'DEPRECATED|deprecated|DEPRECATION', source, re.IGNORECASE):
                          is_deprecated = True
                          # Try to extract date
                          date_match = re.search(r'(\d{4}-\d{2}-\d{2})', source)
                          if date_match:
                              deprecation_date = date_match.group(1)
                          break
              
              if is_deprecated:
                  print(f"üìÖ Found deprecated notebook: {notebook_path}")
                  
                  # Create deprecation warning banner
                  if not deprecation_date:
                      deprecation_date = "unspecified date"
                      date_text = "This notebook is deprecated and may be removed in the future."
                  else:
                      try:
                          dep_date = datetime.strptime(deprecation_date, '%Y-%m-%d')
                          if dep_date <= datetime.now():
                              date_text = f"This notebook was deprecated on <strong>{deprecation_date}</strong> and may be moved or removed."
                          else:
                              date_text = f"This notebook is scheduled for deprecation on <strong>{deprecation_date}</strong>."
                      except:
                          date_text = f"This notebook is deprecated (target date: {deprecation_date})."
                  
                  deprecation_warning_cell = {
                      "cell_type": "markdown",
                      "metadata": {
                          "tags": ["deprecation-warning"]
                      },
                      "source": [
                          "<div style='background-color: #f8d7da; border: 1px solid #f5c6cb; border-radius: 4px; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545;'>\n",
                          "<h3 style='color: #721c24; margin-top: 0;'>üö® DEPRECATED NOTEBOOK</h3>\n",
                          f"<p style='color: #721c24; margin-bottom: 5px;'><strong>{date_text}</strong></p>\n",
                          "<p style='color: #721c24; margin-bottom: 0;'>Please migrate to newer alternatives or contact maintainers before using this notebook in production.</p>\n",
                          "<p style='color: #721c24; margin-bottom: 0; font-size: 0.9em;'><em>This warning was automatically generated during documentation build.</em></p>\n",
                          "</div>\n"
                      ]
                  }
                  
                  # Check if deprecation warning already exists
                  has_deprecation_warning = False
                  for cell in nb.get('cells', []):
                      if cell.get('cell_type') == 'markdown' and 'tags' in cell.get('metadata', {}):
                          if 'deprecation-warning' in cell['metadata']['tags']:
                              has_deprecation_warning = True
                              break
                  
                  # Add deprecation warning at the beginning if not already present
                  if not has_deprecation_warning:
                      nb['cells'].insert(0, deprecation_warning_cell)
                      
                      with open(notebook_path, 'w', encoding='utf-8') as f:
                          json.dump(nb, f, indent=2, ensure_ascii=False)
                      
                      print(f"‚úÖ Added deprecation warning to {notebook_path}")
                  else:
                      print(f"‚ÑπÔ∏è Deprecation warning already exists in {notebook_path}")
              else:
                  print(f"‚úÖ No deprecation found in {notebook_path}")
                  
          except Exception as e:
              print(f"‚ùå Error processing {notebook_path}: {e}")
          EOF
              
              # Run the deprecation check and warning addition
              python add_deprecation_warning.py "$notebook"
              rm -f add_deprecation_warning.py
            fi
          done
          
          echo "‚úÖ Deprecation warning check completed"
          
      - name: Set up Python environment with micromamba
        uses: mamba-org/setup-micromamba@v2.0.4
        with:
          environment-name: docs-env
          init-shell: bash
          create-args: "python=${{ inputs.python-version }} pip jupyter-book sphinx"
          cache-environment: false

      - name: Install documentation dependencies
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate docs-env
          echo "üìö Installing documentation dependencies"
          pip install --upgrade jupyter-book sphinx
          
      - name: Build JupyterBook documentation
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate docs-env
          echo "üìñ Building JupyterBook documentation"
          
          # Clean any existing build directory
          rm -rf _build
          
          # Build the documentation (don't specify --path-output to use default _build location)
          jupyter-book build .
          echo "‚úÖ JupyterBook documentation built successfully"
          
      - name: Run post-processing script
        if: inputs.post-processing-script != ''
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba activate docs-env
          echo "üîß Running post-processing script: ${{ inputs.post-processing-script }}"
          if [ -f "${{ inputs.post-processing-script }}" ]; then
            chmod +x "${{ inputs.post-processing-script }}"
            "${{ inputs.post-processing-script }}"
            echo "‚úÖ Post-processing completed"
          else
            echo "‚ö†Ô∏è Post-processing script not found: ${{ inputs.post-processing-script }}"
          fi

      - name: Deploy to GitHub Pages
        if: inputs.execution-mode == 'merge' || inputs.trigger-event == 'html' || inputs.trigger-event == 'all'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./_build/html
          cname: ${{ vars.PAGES_CNAME || '' }}
          commit_message: "Deploy documentation from executed notebooks [skip ci]"

  # Deprecation Management
  manage-deprecation:
    needs: setup-matrix
    if: inputs.trigger-event == 'deprecate' || inputs.execution-mode == 'scheduled'
    runs-on: ubuntu-24.04
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
          
      - name: Install GitHub CLI
        if: inputs.trigger-event == 'deprecate'
        run: |
          sudo apt-get update
          sudo apt-get install gh -y
          echo "‚úÖ GitHub CLI installed"
          
      - name: Tag notebook for deprecation
        if: inputs.trigger-event == 'deprecate' && inputs.single-notebook != ''
        run: |
          input_notebook="${{ inputs.single-notebook }}"
          deprecation_date=$(date -d "+${{ inputs.deprecation-days }} days" +%Y-%m-%d)
          
          echo "üè∑Ô∏è Tagging notebook for deprecation: $input_notebook"
          echo "üìÖ Deprecation date: $deprecation_date"
          
          # Use path discovery logic like in setup-matrix
          if [[ "$input_notebook" == *"/"* ]]; then
            # Full path provided
            notebook="$input_notebook"
            echo "üìÅ Full path provided: $notebook"
          else
            # Just filename provided - find the full path
            echo "üîç Filename only provided, searching for: $input_notebook"
            notebook=$(find notebooks/ -name "$input_notebook" -type f | head -1)
            if [ -z "$notebook" ]; then
              echo "‚ùå Notebook not found: $input_notebook"
              echo "üìÇ Available notebooks:"
              find notebooks/ -name '*.ipynb' | head -10
              echo "üí° Tip: Provide either the filename or full path relative to repository root"
              exit 1
            fi
            echo "‚úÖ Found notebook at: $notebook"
          fi
          
          # Final check that the resolved notebook exists
          if [ ! -f "$notebook" ]; then
            echo "‚ùå Error: Resolved notebook file not found: $notebook"
            exit 1
          fi
          
          # Create a deprecation branch
          deprecation_branch="deprecate-$(basename "$notebook" .ipynb)-$(date +%Y%m%d-%H%M%S)"
          echo "üåø Creating deprecation branch: $deprecation_branch"
          git checkout -b "$deprecation_branch"
          
          # Add deprecation metadata to notebook
          python3 << EOF
          import json
          import sys
          from datetime import datetime, timedelta
          
          notebook_path = "$notebook"
          days = ${{ inputs.deprecation-days }}
          
          # Verify file exists before processing
          import os
          if not os.path.exists(notebook_path):
              print(f"‚ùå Error: File not found: {notebook_path}")
              sys.exit(1)
          
          with open(notebook_path, 'r') as f:
              nb = json.load(f)
          
          deprecation_date = (datetime.now() + timedelta(days=days)).strftime('%Y-%m-%d')
          
          # Add deprecation metadata to notebook
          if 'metadata' not in nb:
              nb['metadata'] = {}
          
          nb['metadata']['deprecated'] = {
              'status': 'deprecated',
              'date': deprecation_date,
              'message': f'This notebook is scheduled for deprecation on {deprecation_date}'
          }
          
          # Add a deprecation tag cell for backward compatibility
          deprecation_cell = {
              "cell_type": "markdown",
              "metadata": {
                  "tags": ["deprecated"],
                  "deprecation": {
                      "date": deprecation_date,
                      "status": "deprecated"
                  }
              },
              "source": [
                  f"<!-- DEPRECATED: This notebook is scheduled for deprecation on {deprecation_date} -->\n"
              ]
          }
          
          # Insert at the beginning
          nb['cells'].insert(0, deprecation_cell)
          
          with open(notebook_path, 'w') as f:
              json.dump(nb, f, indent=2)
          
          print(f"‚úÖ Added deprecation metadata to {notebook_path}")
          EOF
          
          # Commit the changes to the deprecation branch
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add "$notebook"
          git commit -m "Mark notebook as deprecated: $notebook

          This notebook is scheduled for deprecation on $deprecation_date.
          
          - Added deprecation metadata to notebook
          - Added deprecation tag cell
          - Requires team review before merging
          
          Closes #deprecation-request"
          
          # Push the deprecation branch
          git push origin "$deprecation_branch"
          echo "‚úÖ Pushed deprecation branch: $deprecation_branch"
          
          # Create a Pull Request using GitHub CLI
          pr_title="Deprecate notebook: $(basename "$notebook")"
          pr_body="## üìã Deprecation Request

          **Notebook**: \`$notebook\`  
          **Scheduled Deprecation Date**: $deprecation_date  
          **Days until deprecation**: ${{ inputs.deprecation-days }}

          ### Changes Made:
          - ‚úÖ Added deprecation metadata to notebook metadata
          - ‚úÖ Added deprecation tag cell at the beginning of the notebook
          - ‚úÖ Notebook will show deprecation warnings when rendered

          ### Next Steps:
          1. **Review** this deprecation request
          2. **Merge** this PR to finalize the deprecation
          3. **Automatic** HTML documentation will be rebuilt on merge
          4. **GitHub Pages** will be updated with deprecation warnings

          ### Notes:
          - This notebook will continue to work but will show deprecation warnings
          - On the scheduled date, automated processes may remove or archive the notebook
          - Users will be directed to alternative notebooks or resources

          **Please review and approve if this deprecation is appropriate.**"

          # Create the PR (requires GITHUB_TOKEN with proper permissions)
          echo "üîÑ Creating Pull Request for deprecation..."
          
          # First, create the PR without labels to avoid label errors
          pr_url=$(gh pr create \
            --title "$pr_title" \
            --body "$pr_body" \
            --base main \
            --head "$deprecation_branch" 2>&1)
          
          if [ $? -eq 0 ]; then
            echo "‚úÖ Created Pull Request for notebook deprecation"
            echo "üîó PR URL: $pr_url"
            
            # Try to add labels if they exist (non-blocking - wrapped in subshell to prevent script exit)
            (
              echo "üè∑Ô∏è Attempting to add labels..."
              
              # Check what labels exist first
              echo "üìã Checking available repository labels..."
              AVAILABLE_LABELS=$(gh label list --json name --jq '.[].name' 2>/dev/null | tr '\n' ',' || echo "")
              echo "Available labels: $AVAILABLE_LABELS"
              
              # Try adding each label individually with better error handling
              for label in "deprecation" "documentation"; do
                if echo "$AVAILABLE_LABELS" | grep -q "$label"; then
                  if gh pr edit "$deprecation_branch" --add-label "$label" 2>/dev/null; then
                    echo "‚úÖ Added '$label' label"
                  else
                    echo "‚ö†Ô∏è Failed to add '$label' label (but continuing)"
                  fi
                else
                  echo "‚ÑπÔ∏è Label '$label' not found in repository - skipping"
                fi
              done
              
              echo "‚úÖ Label assignment completed (PR created successfully regardless of labels)"
            ) || echo "‚ö†Ô∏è Label assignment section failed, but PR was created successfully"
          else
            echo "‚ùå Failed to create Pull Request: $pr_url"
            exit 1
          fi
          
          # Store deprecated notebook to gh-storage for immediate documentation update
          echo "üì¶ Storing deprecated notebook to gh-storage for documentation preview"
          
          # Create a backup copy of the deprecated notebook
          temp_notebook="/tmp/deprecated_$(basename "$notebook")"
          cp "$notebook" "$temp_notebook"
          echo "üìã Backed up deprecated notebook to: $temp_notebook"
          
          # Switch to gh-storage branch
          if git ls-remote --exit-code origin gh-storage >/dev/null 2>&1; then
            echo "üì¶ Using existing gh-storage branch"
            git fetch origin gh-storage
            git checkout gh-storage
          else
            echo "üÜï Creating new gh-storage branch"
            git checkout --orphan gh-storage
            git rm -rf . >/dev/null 2>&1 || true
          fi
          
          # Create directory structure and copy the deprecated notebook from backup
          echo "üìÅ Setting up directory: $(dirname "$notebook")"
          mkdir -p "$(dirname "$notebook")"
          cp "$temp_notebook" "$notebook"
          echo "üìã Copied deprecated notebook from backup: $notebook"
          
          # Stage and commit the deprecated notebook to gh-storage
          git add "$notebook"
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è No changes detected in $notebook on gh-storage"
          else
            echo "‚úÖ Changes detected, committing deprecated notebook to gh-storage"
            git commit -m "Update deprecated notebook $notebook for documentation preview [skip ci]"
            
            # Try regular push first, then pull-rebase-push if conflicts
            if git push origin gh-storage; then
              echo "üöÄ Successfully pushed deprecated notebook to gh-storage"
            else
              echo "‚ö†Ô∏è Push failed due to conflicts, attempting rebase..."
              git pull --rebase origin gh-storage
              git push origin gh-storage
              echo "üöÄ Successfully pushed deprecated notebook to gh-storage after rebase"
            fi
          fi
          
          # Clean up backup file and return to deprecation branch
          rm -f "$temp_notebook"
          git checkout "$deprecation_branch"
          echo "üîÑ Returned to deprecation branch: $deprecation_branch"
          echo "‚úÖ Deprecated notebook stored to gh-storage and PR created"
          echo ""
          echo "üìù Summary:"
          echo "  - Deprecation branch created: $deprecation_branch"
          echo "  - Pull Request created for team review"
          echo "  - Notebook stored to gh-storage for documentation preview"
          echo "  - HTML documentation will be rebuilt automatically on PR merge"

      - name: Check for expired deprecations
        if: inputs.execution-mode == 'scheduled'
        run: |
          echo "üîç Checking for expired deprecated notebooks"
          
          # Find deprecated notebooks
          python3 << 'EOF'
          import json
          import os
          import subprocess
          from datetime import datetime
          from pathlib import Path
          
          def check_notebook_deprecation(notebook_path):
              with open(notebook_path, 'r') as f:
                  nb = json.load(f)
              
              for cell in nb['cells']:
                  if cell['cell_type'] == 'markdown' and 'tags' in cell.get('metadata', {}):
                      if 'deprecated' in cell['metadata']['tags']:
                          source = ''.join(cell['source'])
                          # Extract date from deprecation banner
                          import re
                          date_match = re.search(r'(\d{4}-\d{2}-\d{2})', source)
                          if date_match:
                              dep_date = datetime.strptime(date_match.group(1), '%Y-%m-%d')
                              if dep_date <= datetime.now():
                                  return True, dep_date
              return False, None
          
          deprecated_notebooks = []
          
          for notebook in Path('notebooks').rglob('*.ipynb'):
              is_expired, dep_date = check_notebook_deprecation(notebook)
              if is_expired:
                  deprecated_notebooks.append(str(notebook))
                  print(f"Found expired deprecated notebook: {notebook} (expired: {dep_date})")
          
          if deprecated_notebooks:
              # Create deprecated branch if it doesn't exist
              subprocess.run(['git', 'fetch', 'origin', 'deprecated'], capture_output=True)
              result = subprocess.run(['git', 'checkout', 'deprecated'], capture_output=True)
              if result.returncode != 0:
                  subprocess.run(['git', 'checkout', '--orphan', 'deprecated'])
                  subprocess.run(['git', 'rm', '-rf', '.'])
              
              # Copy deprecated notebooks
              subprocess.run(['git', 'checkout', 'main'])
              for notebook in deprecated_notebooks:
                  subprocess.run(['git', 'checkout', 'deprecated'])
                  subprocess.run(['mkdir', '-p', os.path.dirname(notebook)])
                  subprocess.run(['git', 'checkout', 'main', '--', notebook])
                  subprocess.run(['git', 'add', notebook])
              
              # Commit to deprecated branch
              subprocess.run(['git', 'commit', '-m', f'Move {len(deprecated_notebooks)} expired notebooks to deprecated branch'])
              subprocess.run(['git', 'push', 'origin', 'deprecated'])
              
              # Remove from main branch
              subprocess.run(['git', 'checkout', 'main'])
              for notebook in deprecated_notebooks:
                  subprocess.run(['git', 'rm', notebook])
              
              subprocess.run(['git', 'commit', '-m', f'Remove {len(deprecated_notebooks)} deprecated notebooks from main'])
              subprocess.run(['git', 'push', 'origin', 'main'])
              
              print(f"Moved {len(deprecated_notebooks)} notebooks to deprecated branch")
          else:
              print("No expired deprecated notebooks found")
          EOF

  # Summary and Status
  workflow-summary:
    needs: [setup-matrix, process-notebooks, build-documentation, manage-deprecation]
    if: always()
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
          
      - name: Generate workflow summary
        run: |
          echo "## üìä Unified Notebook CI/CD Summary" >> $GITHUB_STEP_SUMMARY
          echo "*Generated: $(date -u +'%Y-%m-%d %H:%M:%S UTC')*" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### üîß Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Execution Mode**: ${{ inputs.execution-mode }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger Event**: ${{ inputs.trigger-event }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Python Version**: ${{ inputs.python-version }}" >> $GITHUB_STEP_SUMMARY
          if [ -n "${{ inputs.conda-environment }}" ]; then
            echo "- **Custom Conda Environment**: ${{ inputs.conda-environment }}" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -n "${{ inputs.custom-requirements }}" ]; then
            echo "- **Custom Requirements**: ${{ inputs.custom-requirements }}" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -n "${{ inputs.single-notebook }}" ]; then
            echo "- **Single Notebook Target**: \`${{ inputs.single-notebook }}\`" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### üìä Job Results" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status | Duration |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Matrix Setup | ${{ needs.setup-matrix.result }} | - |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.execution-mode }}" != "merge" ] && [ "${{ inputs.trigger-event }}" != "deprecate" ]; then
            echo "| Notebook Processing | ${{ needs.process-notebooks.result }} | - |" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ inputs.trigger-event }}" = "deprecate" ]; then
            echo "| Notebook Processing | Skipped (deprecation mode) | - |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Notebook Processing | Skipped (merge mode) | - |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Documentation Build | ${{ needs.build-documentation.result }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "| Deprecation Management | ${{ needs.manage-deprecation.result }} | - |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.trigger-event }}" = "deprecate" ] && [ "${{ inputs.execution-mode }}" = "on-demand" ]; then
            echo "| Documentation Rebuild | ${{ needs.rebuild-docs-after-deprecation.result }} | - |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### üìù Execution Details" >> $GITHUB_STEP_SUMMARY
          
          # Get the notebooks that were processed (with proper JSON quoting)
          NOTEBOOKS='${{ needs.setup-matrix.outputs.matrix-notebooks }}'
          AFFECTED_DIRS='${{ needs.setup-matrix.outputs.affected-dirs }}'
          
          # Better notebook count logic with robust error handling
          if [ "$NOTEBOOKS" = "null" ] || [ "$NOTEBOOKS" = "" ] || [ "$NOTEBOOKS" = "[]" ]; then
            NOTEBOOK_COUNT=0
          else
            # Try to get count, fallback to 0 if parsing fails
            NOTEBOOK_COUNT=$(echo "$NOTEBOOKS" | jq -r 'length' 2>/dev/null || echo "0")
            if [ "$NOTEBOOK_COUNT" = "null" ] || [ -z "$NOTEBOOK_COUNT" ]; then
              NOTEBOOK_COUNT=0
            fi
          fi
          
          # Show what directories were affected (only if there are any)
          if [ "$AFFECTED_DIRS" != "[]" ] && [ "$AFFECTED_DIRS" != "null" ] && [ "$AFFECTED_DIRS" != "" ]; then
            echo "**üìÅ Affected Directories:**" >> $GITHUB_STEP_SUMMARY
            echo "$AFFECTED_DIRS" | jq -r '.[]' 2>/dev/null | while read -r dir; do
              echo "- \`$dir\`" >> $GITHUB_STEP_SUMMARY
            done || echo "- Could not parse affected directories" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Determine what actually happened based on job results rather than just notebook count
          PROCESS_RESULT="${{ needs.process-notebooks.result }}"
          
          if [ "${{ needs.setup-matrix.outputs.docs-only }}" = "true" ]; then
            echo "**üìñ Documentation-Only Build**" >> $GITHUB_STEP_SUMMARY
            echo "- No notebooks executed - documentation built from existing executed notebooks" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.setup-matrix.outputs.skip-execution }}" = "true" ]; then
            echo "**‚è≠Ô∏è Execution Skipped**" >> $GITHUB_STEP_SUMMARY
            echo "- No notebook processing performed (skip execution flag enabled)" >> $GITHUB_STEP_SUMMARY
          elif [ "$PROCESS_RESULT" = "skipped" ] && [ "${{ inputs.execution-mode }}" = "merge" ]; then
            echo "**ÔøΩ Merge Mode**" >> $GITHUB_STEP_SUMMARY
            echo "- Notebook processing skipped in merge mode (using pre-executed notebooks)" >> $GITHUB_STEP_SUMMARY
          elif [ "$PROCESS_RESULT" = "success" ] || [ "$PROCESS_RESULT" = "failure" ]; then
            # We know notebooks were processed because the job ran
            echo "**üöÄ Notebook Processing Results**" >> $GITHUB_STEP_SUMMARY
            
            if [ "$NOTEBOOK_COUNT" -gt 0 ]; then
              echo "- **Total Notebooks**: $NOTEBOOK_COUNT" >> $GITHUB_STEP_SUMMARY
            else
              echo "- **Notebooks Processed**: Job completed (count unavailable)" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Show what was actually done based on trigger event
            case "${{ inputs.trigger-event }}" in
              "validate")
                echo "- **Operation**: Notebook validation" >> $GITHUB_STEP_SUMMARY
                ;;
              "execute")
                echo "- **Operation**: Notebook execution" >> $GITHUB_STEP_SUMMARY
                ;;
              "security")
                echo "- **Operation**: Security scanning" >> $GITHUB_STEP_SUMMARY
                ;;
              "all")
                echo "- **Operation**: Full pipeline (validation, execution, security)" >> $GITHUB_STEP_SUMMARY
                ;;
              "html")
                echo "- **Operation**: Documentation build" >> $GITHUB_STEP_SUMMARY
                ;;
              "deprecate")
                echo "- **Operation**: Deprecation management" >> $GITHUB_STEP_SUMMARY
                if [ "${{ inputs.execution-mode }}" = "on-demand" ] && [ "${{ needs.rebuild-docs-after-deprecation.result }}" = "success" ]; then
                  echo "- **Documentation**: ‚úÖ Automatically rebuilt and deployed with deprecation warnings" >> $GITHUB_STEP_SUMMARY
                elif [ "${{ inputs.execution-mode }}" = "on-demand" ]; then
                  echo "- **Documentation**: ‚ö†Ô∏è Rebuild was attempted but may have failed" >> $GITHUB_STEP_SUMMARY
                fi
                ;;
              *)
                echo "- **Operation**: Notebook processing" >> $GITHUB_STEP_SUMMARY
                ;;
            esac
            
            # Show result
            if [ "$PROCESS_RESULT" = "success" ]; then
              echo "- **Status**: ‚úÖ SUCCESS - All operations completed without errors" >> $GITHUB_STEP_SUMMARY
            else
              echo "- **Status**: ‚ùå FAILURE - Some operations failed" >> $GITHUB_STEP_SUMMARY
              if [ "${{ inputs.execution-mode }}" = "on-demand" ] && [ "${{ needs.build-documentation.result }}" = "success" ]; then
                echo "- **Documentation**: ‚ö†Ô∏è Generated with warnings - failed notebooks marked with execution warnings" >> $GITHUB_STEP_SUMMARY
              fi
            fi
            
            # Add note about deprecation warnings in documentation
            if [ "${{ needs.build-documentation.result }}" = "success" ]; then
              echo "- **Documentation Warnings**: Deprecated notebooks automatically marked with deprecation banners" >> $GITHUB_STEP_SUMMARY
            fi
            
            # List specific notebooks if we can parse them
            if [ "$NOTEBOOK_COUNT" -gt 0 ] && [ "$NOTEBOOKS" != "[]" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**üìÑ Processed Notebooks:**" >> $GITHUB_STEP_SUMMARY
              if [ "$NOTEBOOK_COUNT" = "1" ]; then
                SINGLE_NOTEBOOK=$(echo "$NOTEBOOKS" | jq -r '.[0]' 2>/dev/null)
                if [ "$SINGLE_NOTEBOOK" != "null" ] && [ -n "$SINGLE_NOTEBOOK" ]; then
                  echo "- \`$SINGLE_NOTEBOOK\`" >> $GITHUB_STEP_SUMMARY
                fi
              else
                echo "$NOTEBOOKS" | jq -r '.[]' 2>/dev/null | while read -r notebook; do
                  if [ -n "$notebook" ] && [ "$notebook" != "null" ]; then
                    echo "- \`$notebook\`" >> $GITHUB_STEP_SUMMARY
                  fi
                done
              fi
            fi
          else
            echo "**üìã No Processing Performed**" >> $GITHUB_STEP_SUMMARY
            echo "- No notebooks matched selection criteria or processing was not required" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add error reporting section if there were failures
          if [ "${{ needs.setup-matrix.result }}" = "failure" ] || [ "${{ needs.process-notebooks.result }}" = "failure" ] || [ "${{ needs.build-documentation.result }}" = "failure" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üö® Error Information" >> $GITHUB_STEP_SUMMARY
            echo "One or more jobs failed. Check the following:" >> $GITHUB_STEP_SUMMARY
            echo "1. **Job Logs**: Click on the failed job(s) above to see detailed error messages" >> $GITHUB_STEP_SUMMARY
            echo "2. **Common Issues**:" >> $GITHUB_STEP_SUMMARY
            echo "   - Missing dependencies in requirements.txt" >> $GITHUB_STEP_SUMMARY
            echo "   - Notebook execution errors (infinite loops, missing data, etc.)" >> $GITHUB_STEP_SUMMARY
            echo "   - Environment setup issues" >> $GITHUB_STEP_SUMMARY
            echo "   - Security vulnerabilities detected" >> $GITHUB_STEP_SUMMARY
            echo "3. **Debugging**: Use on-demand mode to test specific notebooks individually" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Add final status indicator
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Determine overall workflow status
          SETUP_RESULT="${{ needs.setup-matrix.result }}"
          PROCESS_RESULT="${{ needs.process-notebooks.result }}"
          BUILD_RESULT="${{ needs.build-documentation.result }}"
          DEPRECATION_RESULT="${{ needs.manage-deprecation.result }}"
          
          # Count successful and failed jobs
          SUCCESS_COUNT=0
          FAILURE_COUNT=0
          
          # Check each job result
          for result in "$SETUP_RESULT" "$PROCESS_RESULT" "$BUILD_RESULT" "$DEPRECATION_RESULT"; do
            case "$result" in
              "success") SUCCESS_COUNT=$((SUCCESS_COUNT + 1)) ;;
              "failure") FAILURE_COUNT=$((FAILURE_COUNT + 1)) ;;
              "skipped") ;; # Don't count skipped jobs as failures
              "cancelled") FAILURE_COUNT=$((FAILURE_COUNT + 1)) ;;
            esac
          done
          
          # Special handling for process-notebooks in merge mode
          if [ "${{ inputs.execution-mode }}" = "merge" ] && [ "$PROCESS_RESULT" = "skipped" ]; then
            echo "**Note**: Notebook processing was intentionally skipped in merge mode" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "$FAILURE_COUNT" -eq 0 ]; then
            echo "## üéâ Workflow completed successfully!" >> $GITHUB_STEP_SUMMARY
            echo "*All required jobs completed without errors*" >> $GITHUB_STEP_SUMMARY
          elif [ "$SUCCESS_COUNT" -gt 0 ]; then
            echo "## ‚ö†Ô∏è Workflow completed with partial success" >> $GITHUB_STEP_SUMMARY
            echo "*Some jobs succeeded but $FAILURE_COUNT job(s) failed - see error details above*" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ‚ùå Workflow failed" >> $GITHUB_STEP_SUMMARY
            echo "*Multiple critical failures occurred - see error details above*" >> $GITHUB_STEP_SUMMARY
          fi
